REPORT: Optimizing Sleep Stage Classification from EEG Data

INTRODUCTION
Sleep staging from electroencephalography (EEG) is essential for diagnosing sleep disorders and advancing research on circadian rhythms, as well as for the development of wearable sleep‐tracking devices. While manual polysomnography (PSG) remains the gold standard, its reliance on multimodal data (EEG, electrooculography, electromyography, electrocardiography, and respiratory sensors) and labor-intensive scoring make it impractical for large-scale or real-time applications. Automated methods exist but often depend on predefined or assumed in-bed intervals. These methods, although highly sensitive for detecting sleep epochs, typically exhibit low specificity for wake epochs—especially problematic when the subtle frequency differences between relaxed wakefulness and light (N1) sleep are masked by noise. Our project aims to overcome these limitations by optimizing the classification of sleep stages from EEG data, with a particular focus on accurately detecting sleep onset and differentiating wakefulness from sleep in both daytime and nighttime patterns. An added objective is to explore whether the extracted features might serve as meaningful biomarkers for sleep onset and circadian regulation.

PROBLEM DESCRIPTION
Our project intends to optimize sleep stage classification by focusing on the identification of sleep onset. In practice, current methods—primarily designed for in-bed intervals—tend to overclassify sleep due to the predominance of sleep epochs and the similarity in frequency spectra between relaxed wakefulness and N1 sleep. This bias leads to an underestimation of wake time, a significant concern for patients with low sleep efficiency. Moreover, many existing algorithms require explicit prompting of wake and sleep times, which limits their generalizability. By directly extracting features from EEG data on a per-epoch (30-second) basis, we seek to develop classifiers that can operate without such constraints and that may reveal latent biomarkers associated with sleep transitions.

INITIAL PIPELINE
Our initial pipeline is constructed using EEG data from 29 subjects, each recorded with approximately 93 channels in EDF format. Sleep stage labels are provided as text files with one label per 30-second epoch. The pipeline employs a custom data loader (ANPDataLoader) that extracts key metadata (sampling rates, channel labels, and recording durations) and segments the data into 30-second epochs. Two feature extraction approaches have been implemented. First, a power spectral density (PSD) method uses a Butterworth bandpass filter (0.5–40 Hz) and Welch’s method to compute relative band power in the delta, theta, alpha, and beta bands for each electrode. Second, a catch22-based method (via the pycatch22 package) computes 22 canonical time-series features that capture temporal autocorrelation, entropy, and distributional properties. Both approaches are designed to yield one feature vector per electrode per 30-second epoch, thereby aligning with the ground-truth sleep labels.

CURRENT PROGRESS AND BOTTLENECKS
Our pipeline is currently capable of processing the EEG recordings by segmenting them into 30-second epochs and extracting features using both the PSD-based and catch22-based methods. We have validated the pipeline on subsets of data (e.g., processing the first 10 minutes per subject) and ensured that the extracted features are stored in CSV files for subsequent analysis. However, processing time remains a significant bottleneck. In particular, the catch22 extraction—even though implemented in optimized C code—is computationally intensive when applied sequentially across many subjects, epochs, and electrodes. Additionally, reading large EDF files from disk contributes to extended runtimes. These issues become even more critical as we aim to extend our analysis from in-bed intervals to full 24-hour recordings.

FUTURE WORK
Future efforts will focus on both computational optimization and methodological enhancement. We plan to implement parallel processing (using joblib or Python’s multiprocessing) to reduce processing times and enable the analysis of full-day recordings. In parallel, we will extend our dataset to include 24-hour data—similar to the dataset used in recent studies—to eliminate reliance on in-bed intervals and improve classifier generalizability. On the modeling front, we intend to investigate deep learning architectures such as temporal convolutional networks (TCNs), convolutional neural networks (CNNs), and graph neural networks (GNNs). These architectures offer the promise of learning hierarchical representations directly from raw EEG data and may capture subtle transitions (e.g., sleep onset) more effectively than manually engineered features. Ultimately, our goal is to combine the interpretability of engineered features with the predictive power of deep models to develop a robust sleep staging algorithm and to identify potential biomarkers associated with sleep onset and circadian dynamics.

SOURCES:
https://osf.io/r26fh/ (dataset of 29 subjects)
https://time-series-features.gitbook.io/catch22/language-specific-docs/python (Catch22 Python documentation)
https://www.sciencedirect.com/science/article/pii/S2352721823001341?via%3Dihub (Actigraphy paper; using 24-hour segments; data access request pending)
https://link.springer.com/article/10.1007/s10618-019-00647-x (Catch22 paper)
