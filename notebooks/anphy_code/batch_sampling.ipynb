{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pickle, numpy as np, pandas as pd, pyedflib\n",
    "from scipy.signal import butter, filtfilt, resample_poly, iirnotch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notch_filter(data, fs, freq=60, Q=30):\n",
    "    b, a = iirnotch(freq, Q, fs)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def lowpass_filter(data, fs, cutoff=90, order=4):\n",
    "    nyq = fs/2.0\n",
    "    normal_cutoff = cutoff/nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def downsample_window(data, fs, target_fs=200):\n",
    "    return resample_poly(data, target_fs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject folder: EPCTL02\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/Users/tereza/spring_2025/STAT_4830/STAT-4830-GOALZ-project/data/ANPHY-Sleep_data\"\n",
    "subject_dirs = sorted([d for d in os.listdir(data_dir)\n",
    "                       if d.lower().startswith(\"epctl\") and os.path.isdir(os.path.join(data_dir, d))])\n",
    "# subject_batch = subject_dirs[5:6]\n",
    "subject_batch = subject_dirs[0:1]\n",
    "subject_batch = subject_dirs[1:2]\n",
    "for subject in subject_batch:\n",
    "    print(\"Subject folder:\", subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/Users/tereza/spring_2025/STAT_4830/STAT-4830-GOALZ-project/data/ANPHY-Sleep_data\"\n",
    "# subject_dirs = sorted([d for d in os.listdir(data_dir)\n",
    "#                        if d.lower().startswith(\"epctl\") and os.path.isdir(os.path.join(data_dir, d))])\n",
    "\n",
    "# # Split 93 electrodes into 10 groups and select the first group.\n",
    "# electrode_indices = np.arange(93)\n",
    "# electrode_groups = np.array_split(electrode_indices, 10)\n",
    "# first_group = electrode_groups[0]\n",
    "\n",
    "# subject_batch = subject_dirs[0:1]\n",
    "# # subject_batch = subject_dirs[1:2]\n",
    "# # subject_batch = subject_dirs[2:3]\n",
    "# # subject_batch = subject_dirs[3:4] # sub 4\n",
    "\n",
    "# k = 2  # windows per electrode per subject (so k/2 for \"W\" and k/2 for \"N1\")\n",
    "# n_per_stage = k // 2\n",
    "# window_sec = 2   # window spans 2 sec (±1 sec)\n",
    "# half_window_sec = window_sec / 2\n",
    "\n",
    "# for subject in subject_batch:\n",
    "#     subj_path = os.path.join(data_dir, subject)\n",
    "#     csv_files = glob.glob(os.path.join(subj_path, \"*.csv\"))\n",
    "#     edf_files = glob.glob(os.path.join(subj_path, \"*.edf\"))\n",
    "#     if not csv_files or not edf_files:\n",
    "#         print(f\"Skipping {subject}: missing CSV or EDF.\")\n",
    "#         continue\n",
    "#     df = pd.read_csv(csv_files[0], index_col=0)\n",
    "#     df_W = df[df[\"stage\"]==\"W\"]\n",
    "#     df_N1 = df[df[\"stage\"]==\"N1\"]\n",
    "#     if len(df_W) < n_per_stage or len(df_N1) < n_per_stage:\n",
    "#         print(f\"Skipping {subject}: not enough epochs for one stage.\")\n",
    "#         continue\n",
    "#     # fixed random_state for reproducibility.\n",
    "#     sample_W = df_W.sample(n=n_per_stage, random_state=0)[\"time_index\"].values\n",
    "#     sample_N1 = df_N1.sample(n=n_per_stage, random_state=0)[\"time_index\"].values\n",
    "\n",
    "#     reader = pyedflib.EdfReader(edf_files[0])\n",
    "#     fs = reader.getSampleFrequency(0)  # e.g. 1000 Hz\n",
    "#     total_samples = reader.getNSamples()[0]\n",
    "#     n_channels = reader.signals_in_file\n",
    "#     signals = [reader.readSignal(i) for i in range(n_channels)]\n",
    "#     channel_labels = reader.getSignalLabels()\n",
    "#     reader.close()\n",
    "\n",
    "#     subject_windows = {}\n",
    "#     # Process only electrodes in the first group.\n",
    "#     for i in first_group:\n",
    "#         if i >= len(channel_labels):\n",
    "#             continue\n",
    "#         ch_label = channel_labels[i]\n",
    "#         for stage, sample_times in zip([\"W\", \"N1\"], [sample_W, sample_N1]):\n",
    "#             for j, t in enumerate(sample_times):\n",
    "#                 start = int((t - half_window_sec) * fs)\n",
    "#                 end = int((t + half_window_sec) * fs)\n",
    "#                 if start < 0 or end > total_samples:\n",
    "#                     continue\n",
    "#                 win = signals[i][start:end]\n",
    "#                 win = notch_filter(win, fs, freq=60, Q=30)\n",
    "#                 win = lowpass_filter(win, fs, cutoff=90, order=4)\n",
    "#                 ds_win = downsample_window(win, fs, target_fs=200)\n",
    "#                 key = f\"{subject.lower()}_{stage.lower()}_win_{j+1}_{ch_label.replace('-', '').replace(' ', '')}\"\n",
    "#                 # Save both the processed window and the center time index.\n",
    "#                 subject_windows[key] = {\"window\": ds_win, \"time_index\": t}\n",
    "\n",
    "#     out_path = os.path.join(subj_path, \"extracted_windows_group1.pkl\")\n",
    "#     with open(out_path, \"wb\") as f:\n",
    "#         pickle.dump(subject_windows, f)\n",
    "#     print(f\"Saved {len(subject_windows)} windows for {subject} (electrode group 1) at {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/Users/tereza/spring_2025/STAT_4830/STAT-4830-GOALZ-project/data/ANPHY-Sleep_data\"\n",
    "# subject_dirs = sorted([d for d in os.listdir(data_dir)\n",
    "#                        if d.lower().startswith(\"epctl\") and os.path.isdir(os.path.join(data_dir, d))])\n",
    "\n",
    "# # Split 93 electrodes into 10 groups and select the first group.\n",
    "# electrode_indices = np.arange(93)\n",
    "# electrode_groups = np.array_split(electrode_indices, 10)\n",
    "# # first_group = electrode_groups[0]\n",
    "# second_group = electrode_groups[1]\n",
    "\n",
    "# # subject_batch = subject_dirs[3:4] # sub 4 - done\n",
    "# # subject_batch = subject_dirs[4:5]\n",
    "# subject_batch = subject_dirs[5:6]\n",
    "\n",
    "# k = 2  # windows per electrode per subject (so k/2 for \"W\" and k/2 for \"N1\")\n",
    "# n_per_stage = k // 2\n",
    "# window_sec = 2   # window spans 2 sec (±1 sec)\n",
    "# half_window_sec = window_sec / 2\n",
    "\n",
    "# for subject in subject_batch:\n",
    "#     subj_path = os.path.join(data_dir, subject)\n",
    "#     csv_files = glob.glob(os.path.join(subj_path, \"*.csv\"))\n",
    "#     edf_files = glob.glob(os.path.join(subj_path, \"*.edf\"))\n",
    "#     if not csv_files or not edf_files:\n",
    "#         print(f\"Skipping {subject}: missing CSV or EDF.\")\n",
    "#         continue\n",
    "#     df = pd.read_csv(csv_files[0], index_col=0)\n",
    "#     df_W = df[df[\"stage\"]==\"W\"]\n",
    "#     df_N1 = df[df[\"stage\"]==\"N1\"]\n",
    "#     if len(df_W) < n_per_stage or len(df_N1) < n_per_stage:\n",
    "#         print(f\"Skipping {subject}: not enough epochs for one stage.\")\n",
    "#         continue\n",
    "#     # fixed random_state for reproducibility.\n",
    "#     sample_W = df_W.sample(n=n_per_stage, random_state=0)[\"time_index\"].values\n",
    "#     sample_N1 = df_N1.sample(n=n_per_stage, random_state=0)[\"time_index\"].values\n",
    "\n",
    "#     reader = pyedflib.EdfReader(edf_files[0])\n",
    "#     fs = reader.getSampleFrequency(0)  # e.g. 1000 Hz\n",
    "#     total_samples = reader.getNSamples()[0]\n",
    "#     n_channels = reader.signals_in_file\n",
    "#     signals = [reader.readSignal(i) for i in range(n_channels)]\n",
    "#     channel_labels = reader.getSignalLabels()\n",
    "#     reader.close()\n",
    "\n",
    "#     subject_windows = {}\n",
    "#     # Process only electrodes in the first group.\n",
    "#     for i in second_group:\n",
    "#         if i >= len(channel_labels):\n",
    "#             continue\n",
    "#         ch_label = channel_labels[i]\n",
    "#         for stage, sample_times in zip([\"W\", \"N1\"], [sample_W, sample_N1]):\n",
    "#             for j, t in enumerate(sample_times):\n",
    "#                 start = int((t - half_window_sec) * fs)\n",
    "#                 end = int((t + half_window_sec) * fs)\n",
    "#                 if start < 0 or end > total_samples:\n",
    "#                     continue\n",
    "#                 win = signals[i][start:end]\n",
    "#                 win = notch_filter(win, fs, freq=60, Q=30)\n",
    "#                 win = lowpass_filter(win, fs, cutoff=90, order=4)\n",
    "#                 ds_win = downsample_window(win, fs, target_fs=200)\n",
    "#                 key = f\"{subject.lower()}_{stage.lower()}_win_{j+1}_{ch_label.replace('-', '').replace(' ', '')}\"\n",
    "#                 # Save both the processed window and the center time index.\n",
    "#                 subject_windows[key] = {\"window\": ds_win, \"time_index\": t}\n",
    "\n",
    "#     out_path = os.path.join(subj_path, \"extracted_windows_group2.pkl\")\n",
    "#     with open(out_path, \"wb\") as f:\n",
    "#         pickle.dump(subject_windows, f)\n",
    "#     print(f\"Saved {len(subject_windows)} windows for {subject} (electrode group 2) at {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20 windows for EPCTL09 (electrode group 3) at /Users/tereza/spring_2025/STAT_4830/STAT-4830-GOALZ-project/data/ANPHY-Sleep_data/EPCTL09/extracted_windows_group3.pkl\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"/Users/tereza/spring_2025/STAT_4830/STAT-4830-GOALZ-project/data/ANPHY-Sleep_data\"\n",
    "# subject_dirs = sorted([d for d in os.listdir(data_dir)\n",
    "#                        if d.lower().startswith(\"epctl\") and os.path.isdir(os.path.join(data_dir, d))])\n",
    "\n",
    "# # Split 93 electrodes into 10 groups and select the first group.\n",
    "# electrode_indices = np.arange(93)\n",
    "# electrode_groups = np.array_split(electrode_indices, 10)\n",
    "# # first_group = electrode_groups[0]\n",
    "# group = electrode_groups[2]\n",
    "\n",
    "# # subject_batch = subject_dirs[6:7] \n",
    "# # subject_batch = subject_dirs[7:8]\n",
    "# subject_batch = subject_dirs[8:9]\n",
    "\n",
    "# k = 2  # windows per electrode per subject (so k/2 for \"W\" and k/2 for \"N1\")\n",
    "# n_per_stage = k // 2\n",
    "# window_sec = 2   # window spans 2 sec (±1 sec)\n",
    "# half_window_sec = window_sec / 2\n",
    "\n",
    "# for subject in subject_batch:\n",
    "#     subj_path = os.path.join(data_dir, subject)\n",
    "#     csv_files = glob.glob(os.path.join(subj_path, \"*.csv\"))\n",
    "#     edf_files = glob.glob(os.path.join(subj_path, \"*.edf\"))\n",
    "#     if not csv_files or not edf_files:\n",
    "#         print(f\"Skipping {subject}: missing CSV or EDF.\")\n",
    "#         continue\n",
    "#     df = pd.read_csv(csv_files[0], index_col=0)\n",
    "#     df_W = df[df[\"stage\"]==\"W\"]\n",
    "#     df_N1 = df[df[\"stage\"]==\"N1\"]\n",
    "#     if len(df_W) < n_per_stage or len(df_N1) < n_per_stage:\n",
    "#         print(f\"Skipping {subject}: not enough epochs for one stage.\")\n",
    "#         continue\n",
    "#     sample_W = df_W.sample(n=n_per_stage, random_state=1)[\"time_index\"].values\n",
    "#     sample_N1 = df_N1.sample(n=n_per_stage, random_state=1)[\"time_index\"].values\n",
    "\n",
    "#     reader = pyedflib.EdfReader(edf_files[0])\n",
    "#     fs = reader.getSampleFrequency(0)  # e.g. 1000 Hz\n",
    "#     total_samples = reader.getNSamples()[0]\n",
    "#     n_channels = reader.signals_in_file\n",
    "#     signals = [reader.readSignal(i) for i in range(n_channels)]\n",
    "#     channel_labels = reader.getSignalLabels()\n",
    "#     reader.close()\n",
    "\n",
    "#     subject_windows = {}\n",
    "#     # Process only electrodes in the first group.\n",
    "#     for i in group:\n",
    "#         if i >= len(channel_labels):\n",
    "#             continue\n",
    "#         ch_label = channel_labels[i]\n",
    "#         for stage, sample_times in zip([\"W\", \"N1\"], [sample_W, sample_N1]):\n",
    "#             for j, t in enumerate(sample_times):\n",
    "#                 start = int((t - half_window_sec) * fs)\n",
    "#                 end = int((t + half_window_sec) * fs)\n",
    "#                 if start < 0 or end > total_samples:\n",
    "#                     continue\n",
    "#                 win = signals[i][start:end]\n",
    "#                 win = notch_filter(win, fs, freq=60, Q=30)\n",
    "#                 win = lowpass_filter(win, fs, cutoff=90, order=4)\n",
    "#                 ds_win = downsample_window(win, fs, target_fs=200)\n",
    "#                 key = f\"{subject.lower()}_{stage.lower()}_win_{j+1}_{ch_label.replace('-', '').replace(' ', '')}\"\n",
    "#                 # Save both the processed window and the center time index.\n",
    "#                 subject_windows[key] = {\"window\": ds_win, \"time_index\": t}\n",
    "\n",
    "#     out_path = os.path.join(subj_path, \"extracted_windows_group3.pkl\")\n",
    "#     with open(out_path, \"wb\") as f:\n",
    "#         pickle.dump(subject_windows, f)\n",
    "#     print(f\"Saved {len(subject_windows)} windows for {subject} (electrode group 3) at {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/Users/tereza/spring_2025/STAT_4830/STAT-4830-GOALZ-project/data/ANPHY-Sleep_data\"\n",
    "# subject_dirs = sorted([d for d in os.listdir(data_dir)\n",
    "#                        if d.lower().startswith(\"epctl\") and os.path.isdir(os.path.join(data_dir, d))])\n",
    "\n",
    "# # Split 93 electrodes into 10 groups and select the first group.\n",
    "# electrode_indices = np.arange(93)\n",
    "# electrode_groups = np.array_split(electrode_indices, 10)\n",
    "# # first_group = electrode_groups[0]\n",
    "# group = electrode_groups[3]\n",
    "\n",
    "# # subject_batch = subject_dirs[9:10] # sub 4 - done\n",
    "# subject_batch = subject_dirs[10:11]\n",
    "# # subject_batch = subject_dirs[11:12]\n",
    "\n",
    "# k = 2  # windows per electrode per subject (so k/2 for \"W\" and k/2 for \"N1\")\n",
    "# n_per_stage = k // 2\n",
    "# window_sec = 2   # window spans 2 sec (±1 sec)\n",
    "# half_window_sec = window_sec / 2\n",
    "\n",
    "# for subject in subject_batch:\n",
    "#     subj_path = os.path.join(data_dir, subject)\n",
    "#     csv_files = glob.glob(os.path.join(subj_path, \"*.csv\"))\n",
    "#     edf_files = glob.glob(os.path.join(subj_path, \"*.edf\"))\n",
    "#     if not csv_files or not edf_files:\n",
    "#         print(f\"Skipping {subject}: missing CSV or EDF.\")\n",
    "#         continue\n",
    "#     df = pd.read_csv(csv_files[0], index_col=0)\n",
    "#     df_W = df[df[\"stage\"]==\"W\"]\n",
    "#     df_N1 = df[df[\"stage\"]==\"N1\"]\n",
    "#     if len(df_W) < n_per_stage or len(df_N1) < n_per_stage:\n",
    "#         print(f\"Skipping {subject}: not enough epochs for one stage.\")\n",
    "#         continue\n",
    "#     # fixed random_state for reproducibility.\n",
    "#     sample_W = df_W.sample(n=n_per_stage, random_state=2)[\"time_index\"].values\n",
    "#     sample_N1 = df_N1.sample(n=n_per_stage, random_state=2)[\"time_index\"].values\n",
    "\n",
    "#     reader = pyedflib.EdfReader(edf_files[0])\n",
    "#     fs = reader.getSampleFrequency(0)  # e.g. 1000 Hz\n",
    "#     total_samples = reader.getNSamples()[0]\n",
    "#     n_channels = reader.signals_in_file\n",
    "#     signals = [reader.readSignal(i) for i in range(n_channels)]\n",
    "#     channel_labels = reader.getSignalLabels()\n",
    "#     reader.close()\n",
    "\n",
    "#     subject_windows = {}\n",
    "#     for i in group:\n",
    "#         if i >= len(channel_labels):\n",
    "#             continue\n",
    "#         ch_label = channel_labels[i]\n",
    "#         for stage, sample_times in zip([\"W\", \"N1\"], [sample_W, sample_N1]):\n",
    "#             for j, t in enumerate(sample_times):\n",
    "#                 start = int((t - half_window_sec) * fs)\n",
    "#                 end = int((t + half_window_sec) * fs)\n",
    "#                 if start < 0 or end > total_samples:\n",
    "#                     continue\n",
    "#                 win = signals[i][start:end]\n",
    "#                 win = notch_filter(win, fs, freq=60, Q=30)\n",
    "#                 win = lowpass_filter(win, fs, cutoff=90, order=4)\n",
    "#                 ds_win = downsample_window(win, fs, target_fs=200)\n",
    "#                 key = f\"{subject.lower()}_{stage.lower()}_win_{j+1}_{ch_label.replace('-', '').replace(' ', '')}\"\n",
    "#                 # Save both the processed window and the center time index.\n",
    "#                 subject_windows[key] = {\"window\": ds_win, \"time_index\": t}\n",
    "\n",
    "#     out_path = os.path.join(subj_path, \"extracted_windows_group4.pkl\")\n",
    "#     with open(out_path, \"wb\") as f:\n",
    "#         pickle.dump(subject_windows, f)\n",
    "#     print(f\"Saved {len(subject_windows)} windows for {subject} (electrode group 4) at {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnt_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
