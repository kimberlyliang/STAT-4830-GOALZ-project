{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-gn-s325CKz_"},"outputs":[],"source":["import os\n","import sys\n","import glob\n","import traceback\n","from pathlib import Path\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14641,"status":"ok","timestamp":1745824614449,"user":{"displayName":"Stefan Zaharia","userId":"12712148834365431848"},"user_tz":240},"id":"EjXulI9hCMLD","outputId":"497b39c1-ba76-4855-e224-7de27145bfac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1745827551062,"user":{"displayName":"Stefan Zaharia","userId":"12712148834365431848"},"user_tz":240},"id":"rroo37URB373","outputId":"9e1da3fb-832d-465e-e4b4-1c03ac272e5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using base directory: /content/drive/MyDrive/4830_project/sleepedf_data\n","Created directory: /content/drive/MyDrive/4830_project/sleepedf_data/hybrid_model_results/plots\n","Created directory: /content/drive/MyDrive/4830_project/sleepedf_data/hybrid_model_results/models\n","Created directory: /content/drive/MyDrive/4830_project/sleepedf_data/hybrid_model_results/metrics\n","Checking directory access:\n","Using device: cuda\n"]}],"source":["# -------------------------\n","# ==== Initialization ====\n","# -------------------------\n","\n","from pathlib import Path\n","# print(os.environ[\"HOME\"])\n","BASE = Path(\"/content/drive/MyDrive/4830_project/sleepedf_data\")\n","print(f\"Using base directory: {BASE!s}\")\n","# BASE = Path(\"/home1/k/kimliang/sleep/sleep_staging/data\")\n","# BASE = \"/Users/kimberly/Documents/STAT4830/STAT-4830-GOALZ-project/data\"\n","\n","PROCESSED_DATA_DIR = BASE/\"processed_sleepedf\"\n","CATCH22_DATA_DIR   = BASE/\"c22_processed_sleepedf\"\n","PSD_DATA_DIR   = BASE/\"features_psd_sleep_edf\"\n","RESULTS_DIR        = BASE/\"hybrid_model_results\"\n","\n","RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n","for sub in [\"plots\", \"models\", \"metrics\"]:\n","    (RESULTS_DIR/sub).mkdir(parents=True, exist_ok=True)\n","    print(f\"Created directory: {RESULTS_DIR/sub}\")\n","\n","print(\"Checking directory access:\")\n","# print(f\"  {PROCESSED_DATA_DIR!s} exists: {PROCESSED_DATA_DIR.exists()}\")\n","# print(f\"  {CATCH22_DATA_DIR!s} exists: {CATCH22_DATA_DIR.exists()}\")\n","\n","# if not PROCESSED_DATA_DIR.exists() or not CATCH22_DATA_DIR.exists():\n","#     print(\"ERROR: Data directories not found. Please re-run preprocessing \u0026 Catch22 steps.\")\n","#     sys.exit(1)\n","\n","# for sub in [\"plots\",\"models\",\"metrics\"]:\n","#     (RESULTS_DIR/sub).mkdir(parents=True, exist_ok=True)\n","\n","# Reproducibility\n","SEED = 42\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Hyperparameters\n","# BATCH_SIZE    = 32\n","# NUM_EPOCHS    = 35\n","# LEARNING_RATE = 1e-5\n","# TRAIN_RATIO   = 0.8\n","# SEQ_LENGTH    = 20\n","# SEQ_STRIDE    = 10\n","BATCH_SIZE    = 32\n","NUM_EPOCHS    = 50\n","LEARNING_RATE = 2e-4\n","TRAIN_RATIO   = 0.8\n","SEQ_LENGTH    = 30  # for better temporal context\n","SEQ_STRIDE    = 5   # for denser temporal sampling\n","\n","# Device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# -------------------------\n","# ==== Utilities  =========\n","# -------------------------\n","def get_true_subject_id(filename):\n","    basename = Path(filename).stem\n","    if basename.startswith((\"SC4\",\"ST7\")):\n","        return basename[:5]\n","    return basename[:6]\n","\n","def group_by_true_subjects(data_dir):\n","    files = glob.glob(str(data_dir/\"*_sequences.npz\"))\n","    subj_map = {}\n","    for f in files:\n","        rid = Path(f).stem.split(\"_\")[0]\n","        subj = get_true_subject_id(rid)\n","        subj_map.setdefault(subj, []).append(rid)\n","    return subj_map\n","\n","def split_true_subjects(data_dir, train_ratio=TRAIN_RATIO, random_state=SEED):\n","    subj_map = group_by_true_subjects(data_dir)\n","    subs = list(subj_map.keys())\n","    np.random.seed(random_state)\n","    np.random.shuffle(subs)\n","    n_train = int(len(subs)*train_ratio)\n","    train_subs = subs[:n_train]\n","    test_subs  = subs[n_train:]\n","    train_ids = [rid for s in train_subs for rid in subj_map[s]]\n","    test_ids  = [rid for s in test_subs  for rid in subj_map[s]]\n","    return train_ids, test_ids, train_subs, test_subs\n","\n","# -------------------------\n","# ==== Dataset    =========\n","# -------------------------\n","class HybridSleepDataset(Dataset):\n","    def __init__(self, raw_dir, c22_dir, psd_dir, recording_ids=None):\n","        all_raw = glob.glob(str(raw_dir/\"*_sequences.npz\"))\n","        all_c22 = glob.glob(str(c22_dir  /\"*_c22.csv\"))\n","        all_psd = glob.glob(str(psd_dir  /\"*_psd.npz\"))\n","        if recording_ids is not None:\n","            all_raw = [p for p in all_raw if any(rid in p for rid in recording_ids)]\n","            all_c22 = [p for p in all_c22 if any(rid in p for rid in recording_ids)]\n","            all_psd = [p for p in all_psd if any(rid in p for rid in recording_ids)]\n","        self.raw_map = {Path(p).stem.split(\"_\")[0]: p for p in all_raw}\n","        self.c22_map = {Path(p).stem.split(\"_\")[0]: p for p in all_c22}\n","        self.psd_map = {Path(p).stem.split(\"_\")[0]: p for p in all_psd}\n","        common = sorted(set(self.raw_map) \u0026 set(self.c22_map) \u0026 set(self.psd_map))\n","        if not common:\n","            raise ValueError(\"No overlapping recordings between raw \u0026 Catch22!\")\n","        self.recording_ids = common\n","\n","        seq_list, c22_list, psd_list, lbl_list = [], [], [], []\n","        for rid in common:\n","            # load raw\n","            data = np.load(self.raw_map[rid])\n","            seqs, labels = data[\"sequences\"], data[\"seq_labels\"]\n","            # load catch22\n","            df = pd.read_csv(self.c22_map[rid])\n","            feats_c22 = df.drop(columns=[\"label\"]).values\n","            # psd features\n","            arr = np.load(self.psd_map[rid])\n","            feats_psd = arr[\"psd\"] if \"psd\" in arr else arr[arr.files[0]]\n","            # if mismatch, pad/truncate\n","            n_seq = seqs.shape[0]\n","            expected = n_seq * SEQ_LENGTH\n","            def align(feats):\n","                if feats.shape[0] != expected:\n","                    feat_dim = feats.shape[1]\n","                    newf = np.zeros((n_seq, SEQ_LENGTH, feat_dim), dtype=np.float32)\n","                    for i in range(n_seq):\n","                        start = i * SEQ_STRIDE\n","                        end   = start + SEQ_LENGTH\n","                        if end \u003c= feats.shape[0]:\n","                            newf[i] = feats[start:end]\n","                        else:\n","                            avail = feats.shape[0] - start\n","                            if avail\u003e0:\n","                                newf[i,:avail] = feats[start:]\n","                                newf[i,avail:] = feats[start+avail-1]\n","                            else:\n","                                newf[i] = newf[i-1]\n","                    return newf\n","                else:\n","                    return feats.reshape(n_seq, SEQ_LENGTH, -1).astype(np.float32)\n","\n","            feats_c22 = align(feats_c22)\n","            feats_psd = align(feats_psd)\n","\n","            seq_list.append(seqs.astype(np.float32))\n","            c22_list.append(feats_c22)\n","            psd_list.append(feats_psd)\n","            lbl_list.append(labels.astype(np.int64))\n","\n","        self.sequences   = torch.from_numpy(np.concatenate(seq_list,axis=0))\n","        self.c22_feats   = torch.from_numpy(np.concatenate(c22_list,axis=0))\n","        self.psd_feats  = torch.from_numpy(np.concatenate(psd_list, axis=0))\n","        self.seq_labels  = torch.from_numpy(np.concatenate(lbl_list,axis=0))\n","        # self.raw    = torch.from_numpy(np.stack(seqs,   axis=0))  # (N_segments, S, 2, T)\n","        # # self.c22_feats = torch.from_numpy(np.concatenate(c22_list, axis=0))\n","        # self.c22    = torch.from_numpy(np.stack(c22_list,   axis=0))  # (N_segments, S, feat_dim)\n","        # self.labels = torch.from_numpy(np.stack(labels, axis=0))  # (N_segments, S)\n","\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        return (self.sequences[idx],\n","                self.c22_feats[idx],\n","                self.psd_feats[idx],\n","                self.seq_labels[idx])\n","\n","# -------------------------\n","# ==== Model      =========\n","# -------------------------\n","class EpochEncoder(nn.Module):\n","    def __init__(self, embedding_dim=128):\n","        super().__init__()\n","        # More filters and smaller kernels for finer feature detection\n","        self.conv1 = nn.Conv1d(2, 32, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm1d(32)\n","        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm1d(64)\n","        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm1d(128)\n","\n","        # Add a fourth convolutional layer for more depth\n","        self.conv4 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n","        self.bn4 = nn.BatchNorm1d(128)\n","\n","        self.pool = nn.MaxPool1d(2)\n","\n","        # Feature refinement with attention\n","        self.channel_attn = nn.Sequential(\n","            nn.AdaptiveAvgPool1d(1),\n","            nn.Conv1d(128, 32, kernel_size=1),\n","            nn.ReLU(),\n","            nn.Conv1d(32, 128, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","        # Use adaptive pooling to handle any input size\n","        self.adaptive_pool = nn.AdaptiveAvgPool1d(48)\n","\n","        # Fixed output size after adaptive pooling\n","        self.fc = nn.Linear(128 * 48, embedding_dim)\n","        self.ln = nn.LayerNorm(embedding_dim)\n","        self.dropout = nn.Dropout(0.2)\n","\n","        # Debug prints\n","        # print(f\"EpochEncoder initialized with embedding_dim={embedding_dim}\")\n","\n","    def forward(self, x):\n","        B, S, C, T = x.shape\n","        # print(f\"EpochEncoder input shape: B={B}, S={S}, C={C}, T={T}\")\n","\n","        x = x.view(B*S, C, T)\n","        # print(f\"Reshaped to: {x.shape}\")\n","\n","        # First conv block with BN and pooling\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        # print(f\"After first conv block: {x.shape}\")\n","\n","        # Second conv block\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        # print(f\"After second conv block: {x.shape}\")\n","\n","        # Third conv block\n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        # print(f\"After third conv block: {x.shape}\")\n","\n","        # Fourth conv block without pooling for finer features\n","        x = self.conv4(x)\n","        x = self.bn4(x)\n","        x = F.relu(x)\n","        # print(f\"After fourth conv block: {x.shape}\")\n","\n","        # Apply channel attention\n","        attn = self.channel_attn(x)\n","        x = x * attn\n","        # print(f\"After attention: {x.shape}\")\n","\n","        # Use adaptive pooling to get fixed output size\n","        x = self.adaptive_pool(x)\n","        # print(f\"After adaptive pooling: {x.shape}\")\n","\n","        # Flatten and project\n","        x = x.view(B*S, -1)\n","        # print(f\"After flattening: {x.shape}\")\n","\n","        x = self.dropout(F.relu(self.fc(x)))\n","        x = self.ln(x)\n","        # print(f\"After FC and LN: {x.shape}\")\n","\n","        output = x.view(B, S, -1)\n","        # print(f\"EpochEncoder final output shape: {output.shape}\")\n","\n","        return output\n","\n","class C22Encoder(nn.Module):\n","    def __init__(self, input_dim, embedding_dim=64):\n","        super().__init__()\n","        # print(f\"Initializing C22Encoder with input_dim={input_dim}, embedding_dim={embedding_dim}\")\n","\n","        # Initial normalization\n","        self.ln0 = nn.LayerNorm(input_dim)\n","\n","        # Simplified architecture - just use a standard MLP\n","        self.fc1 = nn.Linear(input_dim, 256)\n","        self.ln1 = nn.LayerNorm(256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.ln2 = nn.LayerNorm(128)\n","        self.fc3 = nn.Linear(128, embedding_dim)\n","        self.ln3 = nn.LayerNorm(embedding_dim)\n","\n","        # Increased dropout\n","        self.dropout = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        B, S, D = x.shape\n","        # print(f\"C22Encoder input shape: B={B}, S={S}, D={D}\")\n","\n","        x_flat = x.view(B*S, D)\n","        # print(f\"x_flat shape: {x_flat.shape}\")\n","\n","        # Main encoder path\n","        norm_x = self.ln0(x_flat)\n","        x1 = self.dropout(F.relu(self.ln1(self.fc1(norm_x))))\n","        x2 = self.dropout(F.relu(self.ln2(self.fc2(x1))))\n","        x3 = self.dropout(F.relu(self.ln3(self.fc3(x2))))\n","\n","        # print(f\"C22Encoder output shape before reshape: {x3.shape}\")\n","        output = x3.view(B, S, -1)\n","        # print(f\"C22Encoder final output shape: {output.shape}\")\n","\n","        return output\n","\n","class PSDEncoder(nn.Module):\n","    def __init__(self, input_dim, embedding_dim=64):\n","        super().__init__()\n","        self.ln0 = nn.LayerNorm(input_dim)\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.ln1 = nn.LayerNorm(128)\n","        self.fc2 = nn.Linear(128, embedding_dim)\n","        self.ln2 = nn.LayerNorm(embedding_dim)\n","        self.dropout = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        B,S,D = x.shape\n","        x = x.view(B*S, D)\n","        x = self.dropout(F.relu(self.ln1(self.fc1(self.ln0(x)))))\n","        x = self.dropout(F.relu(self.ln2(self.fc2(x))))\n","        return x.view(B, S, -1)\n","\n","class HybridSleepTransformer(nn.Module):\n","    def __init__(self, c22_dim, psd_dim, raw_emb=128, c22_emb=64, psd_emb=64,\n","                 num_classes=5, num_layers=3, num_heads=8, dropout=0.2, seq_length=30):\n","        super().__init__()\n","        self.seq_length = seq_length\n","        self.epoch_enc = EpochEncoder(raw_emb)\n","        self.c22_enc   = C22Encoder(c22_dim, c22_emb)\n","        self.psd_enc   = PSDEncoder(psd_dim, psd_emb)\n","        # compute combined dim\n","        self.combined_dim = raw_emb + c22_emb + psd_emb\n","\n","        # fusion\n","        self.fusion = nn.Sequential(\n","            nn.Linear(self.combined_dim, self.combined_dim),\n","            nn.LayerNorm(self.combined_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(self.combined_dim, self.combined_dim)\n","        )\n","        self.ln_fusion = nn.LayerNorm(self.combined_dim)\n","        self.pos_encoder = nn.Parameter(torch.randn(1, seq_length, self.combined_dim))\n","        self.class_tokens = nn.Parameter(torch.randn(1, num_classes, self.combined_dim))\n","\n","        enc_layer = nn.TransformerEncoderLayer(\n","            d_model=self.combined_dim,\n","            nhead=num_heads,\n","            dim_feedforward=8*self.combined_dim,\n","            dropout=dropout,\n","            batch_first=True\n","        )\n","        self.transformer = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n","\n","        # auxiliary classifiers\n","        self.aux_raw_classifier = nn.Sequential(\n","            nn.Linear(raw_emb,128),nn.LayerNorm(128),nn.ReLU(),nn.Dropout(dropout),nn.Linear(128,num_classes)\n","        )\n","        self.aux_c22_classifier = nn.Sequential(\n","            nn.Linear(c22_emb,128),nn.LayerNorm(128),nn.ReLU(),nn.Dropout(dropout),nn.Linear(128,num_classes)\n","        )\n","        self.aux_psd_classifier = nn.Sequential(\n","            nn.Linear(psd_emb,128),nn.LayerNorm(128),nn.ReLU(),nn.Dropout(dropout),nn.Linear(128,num_classes)\n","        )\n","\n","        # shared and class-specific heads\n","        self.fc_shared = nn.Linear(self.combined_dim,256)\n","        self.ln_shared = nn.LayerNorm(256)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc_classes = nn.ModuleList([nn.Linear(256,1) for _ in range(num_classes)])\n","\n","        # N1 detector\n","        self.n1_detector = nn.Sequential(nn.Linear(self.combined_dim,128),nn.LayerNorm(128),nn.ReLU())\n","        self.n1_lstm = nn.LSTM(128,64,batch_first=True,bidirectional=True)\n","        self.n1_attn = nn.MultiheadAttention(128,4,batch_first=True)\n","        self.n1_output = nn.Linear(128,1)\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None: nn.init.constant_(m.bias,0)\n","\n","    def forward(self, raw, c22, psd):\n","        r = self.epoch_enc(raw)\n","        c = self.c22_enc(c22)\n","        p = self.psd_enc(psd)\n","        # align sequence lengths\n","        B, Sr, _ = r.shape\n","        _, Sc, _ = c.shape\n","        _, Sp, _ = p.shape\n","        S_min = min(Sr, Sc, Sp)\n","        r, c, p = r[:, :S_min, :], c[:, :S_min, :], p[:, :S_min, :]\n","\n","        # auxiliary preds\n","        aux_r = self.aux_raw_classifier(r)\n","        aux_c = self.aux_c22_classifier(c)\n","        aux_p = self.aux_psd_classifier(p)\n","\n","        # fuse\n","        x = torch.cat([r, c, p], dim=2)\n","        B,S,D = x.shape\n","        x_flat = x.view(B*S, D)\n","        x_fused = F.relu(self.ln_fusion(self.fusion(x_flat)))\n","        x = x_fused.view(B,S,D)\n","        x = x + self.pos_encoder[:, :S, :]\n","        class_tokens = self.class_tokens.expand(B, -1, -1)\n","        x = torch.cat([x, class_tokens], dim=1)\n","        out = self.transformer(x)\n","        seq_out, class_out = out[:, :S, :], out[:, S:, :]\n","\n","        # N1 path\n","        n1_feat = self.n1_detector(seq_out)\n","        n1_lstm, _ = self.n1_lstm(n1_feat)\n","        n1_attn, _ = self.n1_attn(n1_lstm, n1_lstm, n1_lstm)\n","        n1_score = self.n1_output(n1_attn)\n","\n","        shared = self.dropout(F.relu(self.ln_shared(self.fc_shared(seq_out))))\n","        class_outputs = []\n","        for i, fc in enumerate(self.fc_classes):\n","            score = fc(shared)\n","            if i == 1:\n","                score = score + n1_score\n","            class_outputs.append(score)\n","        output = torch.cat(class_outputs, dim=2)\n","\n","        if self.training:\n","            return output, aux_r, aux_c, aux_p\n","        else:\n","            return output\n","\n","# -------------------------\n","# ==== Loss       =========\n","# -------------------------\n","def focal_loss(inputs, targets, alpha_general=0.25, alpha_n1=0.9, gamma=2.5):\n","    \"\"\"\n","    Enhanced Focal Loss with stronger focus on N1 class.\n","    - inputs: logits of shape (B, S, C)\n","    - targets: ground‑truth indices of shape (B, S)\n","    \"\"\"\n","    # Flatten to (N, C) and (N,)\n","    B, S, C = inputs.shape\n","    logits = inputs.view(-1, C)      # (N, C)\n","    tgt    = targets.view(-1)        # (N,)\n","\n","    # Log‑softmax + probabilities\n","    logp = F.log_softmax(logits, dim=1)         # (N, C)\n","    p    = torch.exp(logp).clamp(min=1e-7)      # (N, C)\n","\n","    # Cross‑entropy per sample\n","    ce   = F.nll_loss(logp, tgt, reduction='none')  # (N,)\n","\n","    # p_t = probability of the true class for each sample\n","    pt   = p.gather(1, tgt.unsqueeze(1)).squeeze(1)  # (N,)\n","\n","    # Enhanced alpha weighting for difficult classes\n","    # N1 gets highest weight, but also boost N3 and REM moderately\n","    n1_mask = (tgt == 1).float()\n","    n3_mask = (tgt == 3).float()\n","    rem_mask = (tgt == 4).float()\n","\n","    # Apply different alpha weights to different classes\n","    alpha = alpha_general * (1 - n1_mask - n3_mask - rem_mask) + \\\n","            alpha_n1 * n1_mask + \\\n","            0.5 * n3_mask + \\\n","            0.45 * rem_mask\n","\n","    # Enhanced focal term with higher gamma\n","    loss = alpha * ((1 - pt) ** gamma) * ce   # (N,)\n","\n","    return loss.mean()\n","\n","# -------------------------\n","# ==== Training Loop ======\n","# -------------------------\n","def mixup_batch(raw, c22, psd, labels, alpha=0.2):\n","    \"\"\"Apply mixup augmentation to a batch.\"\"\"\n","    lam = np.random.beta(alpha, alpha) if alpha\u003e0 else 1\n","    batch_size = raw.size(0)\n","    idx = torch.randperm(batch_size).to(raw.device)\n","    mixed_raw = lam * raw + (1 - lam) * raw[idx]\n","    mixed_c22 = lam * c22 + (1 - lam) * c22[idx]\n","    mixed_psd = lam * psd + (1 - lam) * psd[idx]\n","    return mixed_raw, mixed_c22, mixed_psd, labels, labels[idx], lam\n","\n","def train_epoch(model, loader, optimizer, scheduler=None, mixup_alpha=0.2):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for raw, c22, psd, labels in loader:\n","        raw = torch.nan_to_num(raw, nan=0.0, posinf=1e5, neginf=-1e5).to(device)\n","        c22 = torch.nan_to_num(c22, nan=0.0, posinf=1e5, neginf=-1e5).to(device)\n","        psd = torch.nan_to_num(psd, nan=0.0, posinf=1e5, neginf=-1e5).to(device)\n","        labels = labels.to(device)\n","\n","        if np.random.rand() \u003c 0.5:\n","            mixed_raw, mixed_c22, mixed_psd, lbl_a, lbl_b, lam = mixup_batch(raw, c22, psd, labels, alpha=mixup_alpha)\n","            use_mixup = True\n","        else:\n","            mixed_raw, mixed_c22, mixed_psd = raw, c22, psd\n","            lbl_a = labels\n","            use_mixup = False\n","\n","        optimizer.zero_grad()\n","\n","        # Forward pass with auxiliary outputs during training\n","        outputs = model(mixed_raw, mixed_c22, mixed_psd)\n","\n","        outputs = model(mixed_raw, mixed_c22, mixed_psd)\n","        main_preds, aux_r, aux_c, aux_p = outputs\n","\n","        main_loss = focal_loss(main_preds, lbl_a)\n","        if use_mixup:\n","            loss = main_loss \\\n","                + 0.3*(lam*focal_loss(aux_r,lbl_a)+(1-lam)*focal_loss(aux_r,lbl_b)) \\\n","                + 0.3*(lam*focal_loss(aux_c,lbl_a)+(1-lam)*focal_loss(aux_c,lbl_b)) \\\n","                + 0.3*(lam*focal_loss(aux_p,lbl_a)+(1-lam)*focal_loss(aux_p,lbl_b))\n","        else:\n","            loss = main_loss + 0.3*(focal_loss(aux_r,labels)+focal_loss(aux_c,labels)+focal_loss(aux_p,labels))\n","\n","        # Check for numerical stability\n","        if not torch.isfinite(loss):\n","            # print(\"Skipping batch: non-finite loss\")\n","            continue\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Increased from 0.5\n","        optimizer.step()\n","\n","        # Update learning rate if using OneCycleLR or similar\n","        if scheduler is not None and isinstance(scheduler, (\n","            torch.optim.lr_scheduler.OneCycleLR,\n","            torch.optim.lr_scheduler.CyclicLR\n","        )):\n","            scheduler.step()\n","\n","        # Calculate running statistics\n","        running_loss += loss.item() * raw.size(0)\n","\n","        # Calculate accuracy (only for non-mixup batches)\n","        if not use_mixup:\n","            preds = main_preds.argmax(dim=-1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.numel()\n","\n","\n","    avg_loss = running_loss / len(loader.dataset)\n","    accuracy = correct / total if total \u003e 0 else 0\n","\n","    return avg_loss, accuracy\n","\n","def smooth_predictions(predictions, window_size=5):\n","    \"\"\"Apply temporal smoothing to predictions with special handling for N1 class.\n","\n","    Args:\n","        predictions: 1D array of class predictions\n","        window_size: Size of smoothing window (should be odd)\n","\n","    Returns:\n","        1D array of smoothed predictions\n","    \"\"\"\n","    if window_size % 2 == 0:\n","        window_size += 1  # Ensure window size is odd\n","\n","    smoothed = np.copy(predictions)\n","    padded = np.pad(predictions, (window_size//2, window_size//2), mode='edge')\n","\n","    for i in range(len(smoothed)):\n","        window = padded[i:i+window_size]\n","\n","        # Special handling for N1 class (index 1)\n","        if 1 in window:  # If N1 is in the window\n","            n1_count = np.sum(window == 1)\n","            # If N1 appears multiple times or is in the center, preserve it\n","            if n1_count \u003e 1 or window[window_size//2] == 1:\n","                smoothed[i] = 1\n","            # Otherwise use consensus voting\n","            else:\n","                counts = np.bincount(window, minlength=5)\n","                # Exclude N1 from voting if it's just a single occurrence\n","                if counts[1] == 1:\n","                    counts[1] = 0\n","                smoothed[i] = np.argmax(counts)\n","        else:\n","            # For non-N1 windows, use standard mode\n","            smoothed[i] = np.argmax(np.bincount(window, minlength=5))\n","\n","    # Additional rule: prevent isolated W (0) or REM (4) classes\n","    for i in range(1, len(smoothed)-1):\n","        if (smoothed[i] == 0 or smoothed[i] == 4) and smoothed[i-1] == smoothed[i+1] and smoothed[i] != smoothed[i-1]:\n","            smoothed[i] = smoothed[i-1]\n","\n","    return smoothed\n","\n","def smooth_predictions(predictions, window_size=5):\n","    \"\"\"Apply temporal smoothing to predictions with special handling for N1 class.\n","\n","    Args:\n","        predictions: 1D array of class predictions\n","        window_size: Size of smoothing window (should be odd)\n","\n","    Returns:\n","        1D array of smoothed predictions\n","    \"\"\"\n","    if window_size % 2 == 0:\n","        window_size += 1  # Ensure window size is odd\n","\n","    smoothed = np.copy(predictions)\n","    padded = np.pad(predictions, (window_size//2, window_size//2), mode='edge')\n","\n","    for i in range(len(smoothed)):\n","        window = padded[i:i+window_size]\n","\n","        # Special handling for N1 class (index 1)\n","        if 1 in window:  # If N1 is in the window\n","            n1_count = np.sum(window == 1)\n","            # If N1 appears multiple times or is in the center, preserve it\n","            if n1_count \u003e 1 or window[window_size//2] == 1:\n","                smoothed[i] = 1\n","            # Otherwise use consensus voting\n","            else:\n","                counts = np.bincount(window, minlength=5)\n","                # Exclude N1 from voting if it's just a single occurrence\n","                if counts[1] == 1:\n","                    counts[1] = 0\n","                smoothed[i] = np.argmax(counts)\n","        else:\n","            # For non-N1 windows, use standard mode\n","            smoothed[i] = np.argmax(np.bincount(window, minlength=5))\n","\n","    # Additional rule: prevent isolated W (0) or REM (4) classes\n","    for i in range(1, len(smoothed)-1):\n","        if (smoothed[i] == 0 or smoothed[i] == 4) and smoothed[i-1] == smoothed[i+1] and smoothed[i] != smoothed[i-1]:\n","            smoothed[i] = smoothed[i-1]\n","\n","    return smoothed\n","\n","def eval_epoch(model, loader, apply_smoothing=True):\n","    model.eval()\n","    running_loss = 0.0\n","    all_preds, all_labels = [], []\n","    all_raw_preds = []  # Store pre-smoothing predictions\n","\n","    with torch.no_grad():\n","        for raw, c22, psd, labels in loader:\n","            raw = torch.nan_to_num(raw,0.0,1e5,-1e5).to(device)\n","            c22 = torch.nan_to_num(c22,0.0,1e5,-1e5).to(device)\n","            psd = torch.nan_to_num(psd,0.0,1e5,-1e5).to(device)\n","            labels = labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(raw, c22, psd)\n","\n","            # Handle outputs based on model training mode\n","            if isinstance(outputs, tuple):\n","                logits = outputs[0]  # Extract main predictions\n","            else:\n","                logits = outputs\n","\n","            if not torch.isfinite(logits).all():\n","                print(\"Warning: non-finite logits in evaluation\")\n","                continue\n","\n","            # Calculate loss\n","            loss = focal_loss(logits, labels)\n","            running_loss += loss.item() * raw.size(0)\n","\n","            # Get predictions\n","            preds = logits.argmax(dim=-1)\n","\n","            # Store predictions and labels\n","            all_raw_preds.append(preds.cpu().numpy())\n","            all_labels.append(labels.cpu().numpy())\n","\n","    # Return early if no valid predictions\n","    if not all_raw_preds:\n","        return float('nan'), 0.0, 0.0, [], []\n","\n","    # Concatenate and flatten predictions and labels\n","    # Concatenate and flatten predictions and labels\n","    all_raw_preds = np.concatenate(all_raw_preds).ravel()\n","    all_labels = np.concatenate(all_labels).ravel()\n","\n","    # Calculate raw accuracy\n","    raw_acc = (all_raw_preds == all_labels).mean()\n","\n","    # Apply temporal smoothing if requested\n","    if apply_smoothing:\n","        all_smoothed_preds = smooth_predictions(all_raw_preds)\n","        smoothed_acc = (all_smoothed_preds == all_labels).mean()\n","        all_preds = all_smoothed_preds\n","    else:\n","        smoothed_acc = raw_acc\n","        all_preds = all_raw_preds\n","\n","    # Calculate per-class metrics\n","    class_accs = []\n","    for cls in range(5):\n","        mask = (all_labels == cls)\n","        if np.sum(mask) \u003e 0:\n","            cls_acc = (all_preds[mask] == all_labels[mask]).mean()\n","            class_accs.append(cls_acc)\n","        else:\n","            class_accs.append(0.0)\n","\n","    return running_loss/len(loader.dataset), raw_acc, smoothed_acc, all_preds, all_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hGnGp7o_CDqv"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","=== Starting Fold 1/5 ===\n","Class distribution in training set (all epochs):\n","  Wake: 394358 samples (61.9%)\n","  N1: 33714 samples (5.3%)\n","  N2: 129912 samples (20.4%)\n","  N3: 29704 samples (4.7%)\n","  REM: 49112 samples (7.7%)\n","\n","Epoch 1/50\n","Fold1 E1/50:\n","  Loss: train=0.6125, val=0.0845\n","  Acc : raw=0.7783, smoothed=0.7559\n","  F1  : W=0.9232, N1=0.2872, N2=0.6261, N3=0.7233, REM=0.4093\n","  → New best model saved (F1-N1: 0.2872)\n","\n","Epoch 2/50\n","Fold1 E2/50:\n","  Loss: train=0.5186, val=0.0777\n","  Acc : raw=0.8086, smoothed=0.7914\n","  F1  : W=0.9373, N1=0.3311, N2=0.6938, N3=0.6593, REM=0.4837\n","  → New best model saved (F1-N1: 0.3311)\n","\n","Epoch 3/50\n","Fold1 E3/50:\n","  Loss: train=0.4904, val=0.0693\n","  Acc : raw=0.8532, smoothed=0.8420\n","  F1  : W=0.9507, N1=0.3831, N2=0.7475, N3=0.7217, REM=0.7065\n","  → New best model saved (F1-N1: 0.3831)\n","\n","Epoch 4/50\n","Fold1 E4/50:\n","  Loss: train=0.4693, val=0.0650\n","  Acc : raw=0.8672, smoothed=0.8574\n","  F1  : W=0.9568, N1=0.4230, N2=0.7707, N3=0.7377, REM=0.7243\n","  → New best model saved (F1-N1: 0.4230)\n","\n","Epoch 5/50\n","Fold1 E5/50:\n","  Loss: train=0.4545, val=0.0654\n","  Acc : raw=0.8754, smoothed=0.8608\n","  F1  : W=0.9591, N1=0.4273, N2=0.7684, N3=0.7857, REM=0.7727\n","  → New best model saved (F1-N1: 0.4273)\n","\n","Epoch 6/50\n","Fold1 E6/50:\n","  Loss: train=0.4303, val=0.0549\n","  Acc : raw=0.8831, smoothed=0.8695\n","  F1  : W=0.9649, N1=0.4629, N2=0.7636, N3=0.7798, REM=0.7860\n","  → New best model saved (F1-N1: 0.4629)\n","\n","Epoch 7/50\n","Fold1 E7/50:\n","  Loss: train=0.4216, val=0.0643\n","  Acc : raw=0.8876, smoothed=0.8729\n","  F1  : W=0.9570, N1=0.4536, N2=0.8140, N3=0.7801, REM=0.8057\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.4629\n","\n","Epoch 8/50\n","Fold1 E8/50:\n","  Loss: train=0.4169, val=0.0553\n","  Acc : raw=0.8803, smoothed=0.8606\n","  F1  : W=0.9618, N1=0.4472, N2=0.7366, N3=0.7808, REM=0.8294\n","  → No improvement for 2/7 epochs. Best F1-N1: 0.4629\n","\n","Epoch 9/50\n","Fold1 E9/50:\n","  Loss: train=0.4093, val=0.0602\n","  Acc : raw=0.8631, smoothed=0.8367\n","  F1  : W=0.9488, N1=0.4043, N2=0.7105, N3=0.8026, REM=0.8099\n","  → No improvement for 3/7 epochs. Best F1-N1: 0.4629\n","\n","Epoch 10/50\n","Fold1 E10/50:\n","  Loss: train=0.4011, val=0.0706\n","  Acc : raw=0.8776, smoothed=0.8577\n","  F1  : W=0.9720, N1=0.4419, N2=0.6730, N3=0.7891, REM=0.8185\n","  → No improvement for 4/7 epochs. Best F1-N1: 0.4629\n","\n","Epoch 11/50\n","Fold1 E11/50:\n","  Loss: train=0.3949, val=0.0534\n","  Acc : raw=0.8713, smoothed=0.8500\n","  F1  : W=0.9609, N1=0.4417, N2=0.6844, N3=0.7835, REM=0.8294\n","  → No improvement for 5/7 epochs. Best F1-N1: 0.4629\n","\n","Epoch 12/50\n","Fold1 E12/50:\n","  Loss: train=0.4023, val=0.0546\n","  Acc : raw=0.8976, smoothed=0.8765\n","  F1  : W=0.9714, N1=0.4809, N2=0.7630, N3=0.8074, REM=0.8236\n","  → New best model saved (F1-N1: 0.4809)\n","\n","Epoch 13/50\n","Fold1 E13/50:\n","  Loss: train=0.4052, val=0.0600\n","  Acc : raw=0.8793, smoothed=0.8574\n","  F1  : W=0.9658, N1=0.4672, N2=0.7016, N3=0.7409, REM=0.8345\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.4809\n","\n","Epoch 14/50\n","Fold1 E14/50:\n","  Loss: train=0.4090, val=0.0534\n","  Acc : raw=0.8764, smoothed=0.8547\n","  F1  : W=0.9633, N1=0.4608, N2=0.6974, N3=0.7428, REM=0.8275\n","  → No improvement for 2/7 epochs. Best F1-N1: 0.4809\n","\n","Epoch 15/50\n","Fold1 E15/50:\n","  Loss: train=0.3952, val=0.0568\n","  Acc : raw=0.8802, smoothed=0.8532\n","  F1  : W=0.9483, N1=0.4226, N2=0.7706, N3=0.8105, REM=0.8474\n","  → No improvement for 3/7 epochs. Best F1-N1: 0.4809\n","\n","Epoch 16/50\n","Fold1 E16/50:\n","  Loss: train=0.3947, val=0.0633\n","  Acc : raw=0.8843, smoothed=0.8633\n","  F1  : W=0.9622, N1=0.4673, N2=0.7478, N3=0.7606, REM=0.8228\n","  → No improvement for 4/7 epochs. Best F1-N1: 0.4809\n","\n","Epoch 17/50\n","Fold1 E17/50:\n","  Loss: train=0.3940, val=0.0707\n","  Acc : raw=0.8928, smoothed=0.8754\n","  F1  : W=0.9695, N1=0.4933, N2=0.7620, N3=0.7562, REM=0.8196\n","  → New best model saved (F1-N1: 0.4933)\n","\n","Epoch 18/50\n","Fold1 E18/50:\n","  Loss: train=0.3896, val=0.0673\n","  Acc : raw=0.8853, smoothed=0.8616\n","  F1  : W=0.9677, N1=0.4544, N2=0.7102, N3=0.8025, REM=0.8329\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.4933\n","\n","Epoch 19/50\n","Fold1 E19/50:\n","  Loss: train=0.3857, val=0.0634\n","  Acc : raw=0.9034, smoothed=0.8839\n","  F1  : W=0.9701, N1=0.5008, N2=0.7821, N3=0.8103, REM=0.8325\n","  → New best model saved (F1-N1: 0.5008)\n","\n","Epoch 20/50\n","Fold1 E20/50:\n","  Loss: train=0.3880, val=0.0643\n","  Acc : raw=0.8992, smoothed=0.8790\n","  F1  : W=0.9696, N1=0.4913, N2=0.7736, N3=0.7748, REM=0.8437\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.5008\n","\n","Epoch 21/50\n","Fold1 E21/50:\n","  Loss: train=0.3824, val=0.0602\n","  Acc : raw=0.9007, smoothed=0.8800\n","  F1  : W=0.9775, N1=0.4761, N2=0.7437, N3=0.8225, REM=0.8235\n","  → No improvement for 2/7 epochs. Best F1-N1: 0.5008\n","\n","Epoch 22/50\n","Fold1 E22/50:\n","  Loss: train=0.3845, val=0.0542\n","  Acc : raw=0.8890, smoothed=0.8708\n","  F1  : W=0.9736, N1=0.4993, N2=0.7252, N3=0.7196, REM=0.8267\n","  → No improvement for 3/7 epochs. Best F1-N1: 0.5008\n","\n","Epoch 23/50\n","Fold1 E23/50:\n","  Loss: train=0.3796, val=0.0712\n","  Acc : raw=0.8930, smoothed=0.8691\n","  F1  : W=0.9654, N1=0.4737, N2=0.7612, N3=0.7690, REM=0.8338\n","  → No improvement for 4/7 epochs. Best F1-N1: 0.5008\n","\n","Epoch 24/50\n","Fold1 E24/50:\n","  Loss: train=0.3756, val=0.0520\n","  Acc : raw=0.9021, smoothed=0.8850\n","  F1  : W=0.9714, N1=0.5023, N2=0.7868, N3=0.7703, REM=0.8506\n","  → New best model saved (F1-N1: 0.5023)\n","\n","Epoch 25/50\n","Fold1 E25/50:\n","  Loss: train=0.3812, val=0.0635\n","  Acc : raw=0.8925, smoothed=0.8715\n","  F1  : W=0.9702, N1=0.4794, N2=0.7382, N3=0.7846, REM=0.8261\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.5023\n","\n","Epoch 26/50\n","Fold1 E26/50:\n","  Loss: train=0.3695, val=0.0638\n","  Acc : raw=0.8887, smoothed=0.8678\n","  F1  : W=0.9675, N1=0.4700, N2=0.7365, N3=0.7946, REM=0.8311\n","  → No improvement for 2/7 epochs. Best F1-N1: 0.5023\n","\n","Epoch 27/50\n","Fold1 E27/50:\n","  Loss: train=0.3774, val=0.0605\n","  Acc : raw=0.9058, smoothed=0.8879\n","  F1  : W=0.9751, N1=0.5030, N2=0.7893, N3=0.7628, REM=0.8435\n","  → New best model saved (F1-N1: 0.5030)\n","\n","Epoch 28/50\n","Fold1 E28/50:\n","  Loss: train=0.3637, val=0.0542\n","  Acc : raw=0.8995, smoothed=0.8798\n","  F1  : W=0.9699, N1=0.4898, N2=0.7802, N3=0.7783, REM=0.8368\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.5030\n","\n","Epoch 29/50\n","Fold1 E29/50:\n","  Loss: train=0.3719, val=0.0670\n","  Acc : raw=0.8910, smoothed=0.8668\n","  F1  : W=0.9680, N1=0.4703, N2=0.7428, N3=0.7791, REM=0.8168\n","  → No improvement for 2/7 epochs. Best F1-N1: 0.5030\n","\n","Epoch 30/50\n","Fold1 E30/50:\n","  Loss: train=0.3682, val=0.0632\n","  Acc : raw=0.8940, smoothed=0.8777\n","  F1  : W=0.9717, N1=0.5051, N2=0.7565, N3=0.7251, REM=0.8424\n","  → New best model saved (F1-N1: 0.5051)\n","\n","Epoch 31/50\n","Fold1 E31/50:\n","  Loss: train=0.3697, val=0.0584\n","  Acc : raw=0.8969, smoothed=0.8761\n","  F1  : W=0.9709, N1=0.4874, N2=0.7526, N3=0.7823, REM=0.8413\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.5051\n","\n","Epoch 32/50\n","Fold1 E32/50:\n","  Loss: train=0.3592, val=0.0593\n","  Acc : raw=0.8966, smoothed=0.8761\n","  F1  : W=0.9665, N1=0.4820, N2=0.7781, N3=0.7794, REM=0.8400\n","  → No improvement for 2/7 epochs. Best F1-N1: 0.5051\n","\n","Epoch 33/50\n","Fold1 E33/50:\n","  Loss: train=0.3607, val=0.0547\n","  Acc : raw=0.9039, smoothed=0.8846\n","  F1  : W=0.9739, N1=0.4996, N2=0.7811, N3=0.7844, REM=0.8279\n","  → No improvement for 3/7 epochs. Best F1-N1: 0.5051\n","\n","Epoch 34/50\n","Fold1 E34/50:\n","  Loss: train=0.3723, val=0.0593\n","  Acc : raw=0.9045, smoothed=0.8856\n","  F1  : W=0.9746, N1=0.5033, N2=0.7812, N3=0.7685, REM=0.8437\n","  → No improvement for 4/7 epochs. Best F1-N1: 0.5051\n","\n","Epoch 35/50\n","Fold1 E35/50:\n","  Loss: train=0.3611, val=0.0621\n","  Acc : raw=0.9061, smoothed=0.8893\n","  F1  : W=0.9730, N1=0.4989, N2=0.8001, N3=0.7782, REM=0.8466\n","  → No improvement for 5/7 epochs. Best F1-N1: 0.5051\n","\n","Epoch 36/50\n","Fold1 E36/50:\n","  Loss: train=0.3525, val=0.0565\n","  Acc : raw=0.9032, smoothed=0.8833\n","  F1  : W=0.9707, N1=0.4877, N2=0.7877, N3=0.8066, REM=0.8300\n","  → No improvement for 6/7 epochs. Best F1-N1: 0.5051\n","\n","Epoch 37/50\n","Fold1 E37/50:\n","  Loss: train=0.3655, val=0.0608\n","  Acc : raw=0.9032, smoothed=0.8818\n","  F1  : W=0.9721, N1=0.4851, N2=0.7785, N3=0.8040, REM=0.8340\n","  → No improvement for 7/7 epochs. Best F1-N1: 0.5051\n","  → Early stopping triggered after 37 epochs\n","\n","Loading best model from epoch 30\n","\n","==\u003e Fold1 final results:\n","  Accuracy: 0.8818\n","  Per-class F1 scores:\n","    W: 0.9721\n","    N1: 0.4851\n","    N2: 0.7785\n","    N3: 0.8040\n","    REM: 0.8340\n","\n","  Confusion Matrix:\n","    W    N1    N2    N3    REM\n","W:   107787  5460   188    17   184\n","N1:     208  7177  1181    73   359\n","N2:      57  6073 21437  1972   696\n","N3:      12   233  1252  7685     7\n","REM:      57  1647   778   181  9819\n","\n","=== Starting Fold 2/5 ===\n","Class distribution in training set (all epochs):\n","  Wake: 397499 samples (61.9%)\n","  N1: 32922 samples (5.1%)\n","  N2: 127354 samples (19.8%)\n","  N3: 33481 samples (5.2%)\n","  REM: 50884 samples (7.9%)\n","\n","Epoch 1/50\n","Fold2 E1/50:\n","  Loss: train=0.6208, val=0.0918\n","  Acc : raw=0.7643, smoothed=0.7459\n","  F1  : W=0.9282, N1=0.3077, N2=0.5887, N3=0.5123, REM=0.0212\n","  → New best model saved (F1-N1: 0.3077)\n","\n","Epoch 2/50\n","Fold2 E2/50:\n","  Loss: train=0.5267, val=0.0806\n","  Acc : raw=0.7967, smoothed=0.7840\n","  F1  : W=0.9294, N1=0.3470, N2=0.6702, N3=0.5638, REM=0.5356\n","  → New best model saved (F1-N1: 0.3470)\n","\n","Epoch 3/50\n","Fold2 E3/50:\n","  Loss: train=0.4899, val=0.0657\n","  Acc : raw=0.8243, smoothed=0.8051\n","  F1  : W=0.9414, N1=0.3830, N2=0.7045, N3=0.5844, REM=0.6111\n","  → New best model saved (F1-N1: 0.3830)\n","\n","Epoch 4/50\n","Fold2 E4/50:\n","  Loss: train=0.4594, val=0.0625\n","  Acc : raw=0.8446, smoothed=0.8251\n","  F1  : W=0.9556, N1=0.4125, N2=0.6627, N3=0.6220, REM=0.7325\n","  → New best model saved (F1-N1: 0.4125)\n","\n","Epoch 5/50\n","Fold2 E5/50:\n","  Loss: train=0.4510, val=0.0524\n","  Acc : raw=0.8466, smoothed=0.8253\n","  F1  : W=0.9545, N1=0.4160, N2=0.6532, N3=0.6339, REM=0.7601\n","  → New best model saved (F1-N1: 0.4160)\n","\n","Epoch 6/50\n","Fold2 E6/50:\n","  Loss: train=0.4418, val=0.0709\n","  Acc : raw=0.8733, smoothed=0.8617\n","  F1  : W=0.9584, N1=0.4507, N2=0.7941, N3=0.6200, REM=0.7298\n","  → New best model saved (F1-N1: 0.4507)\n","\n","Epoch 7/50\n","Fold2 E7/50:\n","  Loss: train=0.4339, val=0.0600\n","  Acc : raw=0.8648, smoothed=0.8443\n","  F1  : W=0.9567, N1=0.4388, N2=0.7447, N3=0.6539, REM=0.7759\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.4507\n","\n","Epoch 8/50\n","Fold2 E8/50:\n","  Loss: train=0.4217, val=0.0656\n","  Acc : raw=0.8617, smoothed=0.8388\n","  F1  : W=0.9495, N1=0.4424, N2=0.7475, N3=0.6541, REM=0.7325\n","  → No improvement for 2/7 epochs. Best F1-N1: 0.4507\n","\n","Epoch 9/50\n","Fold2 E9/50:\n","  Loss: train=0.4109, val=0.0587\n","  Acc : raw=0.8556, smoothed=0.8353\n","  F1  : W=0.9631, N1=0.4259, N2=0.6504, N3=0.6374, REM=0.8182\n","  → No improvement for 3/7 epochs. Best F1-N1: 0.4507\n","\n","Epoch 10/50\n","Fold2 E10/50:\n","  Loss: train=0.4188, val=0.0652\n","  Acc : raw=0.8580, smoothed=0.8374\n","  F1  : W=0.9658, N1=0.4396, N2=0.6379, N3=0.6051, REM=0.8002\n","  → No improvement for 4/7 epochs. Best F1-N1: 0.4507\n","\n","Epoch 11/50\n","Fold2 E11/50:\n","  Loss: train=0.4009, val=0.0640\n","  Acc : raw=0.8418, smoothed=0.8217\n","  F1  : W=0.9421, N1=0.4218, N2=0.7116, N3=0.6049, REM=0.7698\n","  → No improvement for 5/7 epochs. Best F1-N1: 0.4507\n","\n","Epoch 12/50\n","Fold2 E12/50:\n","  Loss: train=0.3999, val=0.0573\n","  Acc : raw=0.8656, smoothed=0.8434\n","  F1  : W=0.9489, N1=0.4477, N2=0.7597, N3=0.6740, REM=0.7983\n","  → No improvement for 6/7 epochs. Best F1-N1: 0.4507\n","\n","Epoch 13/50\n","Fold2 E13/50:\n","  Loss: train=0.3965, val=0.0826\n","  Acc : raw=0.8595, smoothed=0.8338\n","  F1  : W=0.9546, N1=0.4271, N2=0.6792, N3=0.6818, REM=0.8183\n","  → No improvement for 7/7 epochs. Best F1-N1: 0.4507\n","  → Early stopping triggered after 13 epochs\n","\n","Loading best model from epoch 6\n","\n","==\u003e Fold2 final results:\n","  Accuracy: 0.8338\n","  Per-class F1 scores:\n","    W: 0.9546\n","    N1: 0.4271\n","    N2: 0.6792\n","    N3: 0.6818\n","    REM: 0.8183\n","\n","  Confusion Matrix:\n","    W    N1    N2    N3    REM\n","W:   102483  7674   114    12   212\n","N1:     555  8245   362    86   542\n","N2:     849 10737 17514  2984   709\n","N3:     212   265   534  4397     4\n","REM:     112  1902   257     7  8432\n","\n","=== Starting Fold 3/5 ===\n","Class distribution in training set (all epochs):\n","  Wake: 402571 samples (62.6%)\n","  N1: 34094 samples (5.3%)\n","  N2: 127316 samples (19.8%)\n","  N3: 31123 samples (4.8%)\n","  REM: 48056 samples (7.5%)\n","\n","Epoch 1/50\n","Fold3 E1/50:\n","  Loss: train=0.6150, val=0.0985\n","  Acc : raw=0.7605, smoothed=0.7399\n","  F1  : W=0.9241, N1=0.2509, N2=0.6890, N3=0.6055, REM=0.0296\n","  → New best model saved (F1-N1: 0.2509)\n","\n","Epoch 2/50\n","Fold3 E2/50:\n","  Loss: train=0.5179, val=0.0798\n","  Acc : raw=0.8242, smoothed=0.8115\n","  F1  : W=0.9533, N1=0.3048, N2=0.7184, N3=0.6501, REM=0.5898\n","  → New best model saved (F1-N1: 0.3048)\n","\n","Epoch 3/50\n","Fold3 E3/50:\n","  Loss: train=0.4820, val=0.0696\n","  Acc : raw=0.8496, smoothed=0.8399\n","  F1  : W=0.9649, N1=0.3623, N2=0.7403, N3=0.6713, REM=0.6710\n","  → New best model saved (F1-N1: 0.3623)\n","\n","Epoch 4/50\n","Fold3 E4/50:\n","  Loss: train=0.4569, val=0.0751\n","  Acc : raw=0.8371, smoothed=0.8288\n","  F1  : W=0.9549, N1=0.3637, N2=0.7191, N3=0.6582, REM=0.6658\n","  → New best model saved (F1-N1: 0.3637)\n","\n","Epoch 5/50\n","Fold3 E5/50:\n","  Loss: train=0.4462, val=0.0628\n","  Acc : raw=0.8578, smoothed=0.8433\n","  F1  : W=0.9689, N1=0.4229, N2=0.7013, N3=0.6792, REM=0.7365\n","  → New best model saved (F1-N1: 0.4229)\n","\n","Epoch 6/50\n","Fold3 E6/50:\n","  Loss: train=0.4304, val=0.0903\n","  Acc : raw=0.8247, smoothed=0.8172\n","  F1  : W=0.9553, N1=0.4174, N2=0.6532, N3=0.5404, REM=0.7753\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.4229\n","\n","Epoch 7/50\n","Fold3 E7/50:\n","  Loss: train=0.4237, val=0.0699\n","  Acc : raw=0.8817, smoothed=0.8668\n","  F1  : W=0.9720, N1=0.4604, N2=0.7534, N3=0.7142, REM=0.8110\n","  → New best model saved (F1-N1: 0.4604)\n","\n","Epoch 8/50\n","Fold3 E8/50:\n","  Loss: train=0.4075, val=0.0634\n","  Acc : raw=0.8721, smoothed=0.8526\n","  F1  : W=0.9785, N1=0.4426, N2=0.6760, N3=0.6865, REM=0.8011\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.4604\n","\n","Epoch 9/50\n","Fold3 E9/50:\n","  Loss: train=0.4083, val=0.0607\n","  Acc : raw=0.8818, smoothed=0.8635\n","  F1  : W=0.9705, N1=0.4607, N2=0.7574, N3=0.7143, REM=0.7989\n","  → New best model saved (F1-N1: 0.4607)\n","\n","Epoch 10/50\n","Fold3 E10/50:\n","  Loss: train=0.4061, val=0.0826\n","  Acc : raw=0.8397, smoothed=0.8267\n","  F1  : W=0.9713, N1=0.4441, N2=0.5772, N3=0.6897, REM=0.6806\n","  → No improvement for 1/7 epochs. Best F1-N1: 0.4607\n","\n","Epoch 11/50\n"]}],"source":["torch.autograd.set_detect_anomaly(True)\n","\n","# Hyperparameters (updated)\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 50  # Increased from 35\n","LEARNING_RATE = 2e-4  # Increased from 1e-5\n","SEQ_LENGTH = 30  # Increased from 20\n","SEQ_STRIDE = 5   # Decreased from 10 for more temporal context\n","\n","# prepare CV splits\n","subj_map = group_by_true_subjects(PROCESSED_DATA_DIR)\n","subjects = list(subj_map.keys())\n","np.random.seed(SEED)\n","np.random.shuffle(subjects)\n","folds = np.array_split(subjects, 5)\n","\n","# Track metrics for all folds\n","fold_results = {\n","    'accuracy': [],\n","    'f1_n1': [],\n","    'f1_n2': [],\n","    'f1_n3': [],\n","    'f1_rem': [],\n","    'f1_wake': []\n","}\n","\n","# Full per-class results for all folds\n","all_fold_confusion = np.zeros((5, 5))  # 5 classes x 5 classes\n","all_fold_f1 = np.zeros((5, 5))  # 5 folds x 5 classes\n","\n","for k in range(5):\n","    print(f\"\\n=== Starting Fold {k+1}/5 ===\")\n","    test_subs = folds[k]\n","    train_subs = [s for i, f in enumerate(folds) if i!=k for s in f]\n","    train_ids = [rid for s in train_subs for rid in subj_map[s]]\n","    test_ids = [rid for s in test_subs for rid in subj_map[s]]\n","\n","    # Create datasets with updated sequence length\n","    train_ds = HybridSleepDataset(\n","        PROCESSED_DATA_DIR,\n","        CATCH22_DATA_DIR,\n","        PSD_DATA_DIR,\n","        recording_ids=train_ids\n","    )\n","    test_ds = HybridSleepDataset(\n","        PROCESSED_DATA_DIR,\n","        CATCH22_DATA_DIR,\n","        PSD_DATA_DIR,\n","        recording_ids=test_ids\n","    )\n","\n","    # Enhanced weighted sampler with stronger N1 focus\n","    # prev start\n","    # labels = train_ds.seq_labels[:,0].numpy()\n","    # class_counts = np.bincount(labels, minlength=5)\n","\n","    # # Print class distribution\n","    # print(\"Class distribution in training set:\")\n","    # classes = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n","    # for i, cls in enumerate(classes):\n","    #     print(f\"  {cls}: {class_counts[i]} samples ({class_counts[i]/len(labels)*100:.1f}%)\")\n","\n","    # # Enhanced class weights with extra boost for N1\n","    # class_weights = 1.0 / np.sqrt(class_counts + 1e-6)\n","    # # Extra boost for N1 class\n","    # class_weights[1] *= 1.5\n","\n","    # sample_weights = class_weights[labels]\n","    # sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n","    # prev end\n","    # Enhanced weighted sampler with more accurate class distribution\n","\n","    # new start\n","    # Flatten all sequence labels to get true distribution\n","    flat_labels = train_ds.seq_labels.reshape(-1).numpy()\n","    class_counts = np.bincount(flat_labels, minlength=5)\n","\n","    # Print class distribution\n","    print(\"Class distribution in training set (all epochs):\")\n","    classes = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n","    for i, cls in enumerate(classes):\n","        print(f\"  {cls}: {class_counts[i]} samples ({class_counts[i]/len(flat_labels)*100:.1f}%)\")\n","\n","    # Calculate weights based on the true distribution\n","    class_weights = 1.0 / np.sqrt(class_counts + 1e-6)\n","    # Extra boost for N1 class\n","    class_weights[1] *= 1.5\n","\n","    # For sampling, we need weights per sequence\n","    # Using the mean of the class weights for all epochs in each sequence\n","    sequence_weights = np.zeros(len(train_ds))\n","    for i in range(len(train_ds)):\n","        seq_labels = train_ds.seq_labels[i].numpy()\n","        seq_weights = class_weights[seq_labels]\n","        sequence_weights[i] = np.mean(seq_weights)\n","\n","    sampler = WeightedRandomSampler(sequence_weights, len(sequence_weights), replacement=True)\n","    # new end\n","\n","    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n","                              sampler=sampler, num_workers=4, pin_memory=True)\n","    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE,\n","                            shuffle=False, num_workers=4, pin_memory=True)\n","\n","    # Create model with updated architecture\n","    c22_dim = train_ds.c22_feats.shape[-1]\n","    psd_dim = train_ds.psd_feats.shape[-1]\n","    model = HybridSleepTransformer(\n","        c22_dim=c22_dim,\n","        psd_dim=psd_dim,\n","        raw_emb=128,\n","        c22_emb=64,\n","        psd_emb=64,\n","        num_classes=5,\n","        num_layers=3,\n","        num_heads=8,\n","        dropout=0.2,\n","        seq_length=SEQ_LENGTH\n","    ).to(device)\n","\n","    # Optimizer with weight decay\n","    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n","\n","    # Use OneCycleLR for better convergence\n","    scheduler = optim.lr_scheduler.OneCycleLR(\n","        optimizer,\n","        max_lr=LEARNING_RATE,\n","        epochs=NUM_EPOCHS,\n","        steps_per_epoch=len(train_loader),\n","        pct_start=0.3,  # Warm up for 30% of training\n","        div_factor=25,  # Initial LR is max_lr/25\n","        final_div_factor=1000  # End with LR 1000x smaller than max\n","    )\n","\n","    # Early stopping setup\n","    patience = 7\n","    patience_counter = 0\n","    best_f1_n1 = 0  # Track best N1 F1 score specifically\n","    best_loss = float('inf')\n","    best_epoch = 0\n","\n","    # Training loop\n","    for epoch in range(NUM_EPOCHS):\n","        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n","\n","        # Train\n","        train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler)\n","\n","        # Evaluate with smoothing\n","        val_loss, raw_acc, smoothed_acc, val_preds, val_labels = eval_epoch(model, test_loader, apply_smoothing=True)\n","\n","        # Calculate per-class metrics\n","        report = classification_report(val_labels, val_preds, target_names=[\"W\",\"N1\",\"N2\",\"N3\",\"REM\"], output_dict=True)\n","        f1_scores = [report[c]['f1-score'] for c in [\"W\",\"N1\",\"N2\",\"N3\",\"REM\"]]\n","\n","        # Print detailed metrics\n","        print(f\"Fold{k+1} E{epoch+1}/{NUM_EPOCHS}:\")\n","        print(f\"  Loss: train={train_loss:.4f}, val={val_loss:.4f}\")\n","        print(f\"  Acc : raw={raw_acc:.4f}, smoothed={smoothed_acc:.4f}\")\n","        print(f\"  F1  : W={f1_scores[0]:.4f}, N1={f1_scores[1]:.4f}, N2={f1_scores[2]:.4f}, N3={f1_scores[3]:.4f}, REM={f1_scores[4]:.4f}\")\n","\n","        # Adjust learning rate for ReduceLROnPlateau\n","        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau) and np.isfinite(val_loss):\n","            scheduler.step(val_loss)\n","\n","        # Check if this is the best model focused on N1 performance\n","        current_f1_n1 = report['N1']['f1-score']\n","        if current_f1_n1 \u003e best_f1_n1:\n","            best_f1_n1 = current_f1_n1\n","            best_epoch = epoch\n","            patience_counter = 0\n","\n","            # Save best model\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'scheduler_state_dict': scheduler.state_dict() if not isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau) else None,\n","                'val_loss': val_loss,\n","                'smoothed_acc': smoothed_acc,\n","                'f1_scores': f1_scores,\n","            }, RESULTS_DIR/f\"models/best_fold{k+1}.pth\")\n","\n","            print(f\"  → New best model saved (F1-N1: {current_f1_n1:.4f})\")\n","        else:\n","            patience_counter += 1\n","            print(f\"  → No improvement for {patience_counter}/{patience} epochs. Best F1-N1: {best_f1_n1:.4f}\")\n","\n","        # Early stopping\n","        if patience_counter \u003e= patience:\n","            print(f\"  → Early stopping triggered after {epoch+1} epochs\")\n","            break\n","\n","    # Final evaluation on best model\n","    print(f\"\\nLoading best model from epoch {best_epoch+1}\")\n","    # checkpoint = torch.load(RESULTS_DIR/f\"models/best_fold{k+1}.pth\")\n","    # model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Final evaluation with detailed metrics\n","    _, _, final_acc, final_preds, final_labels = eval_epoch(model, test_loader, apply_smoothing=True)\n","    final_report = classification_report(final_labels, final_preds, target_names=[\"W\",\"N1\",\"N2\",\"N3\",\"REM\"], output_dict=True)\n","    final_cm = confusion_matrix(final_labels, final_preds)\n","\n","    # Print final results\n","    print(f\"\\n==\u003e Fold{k+1} final results:\")\n","    print(f\"  Accuracy: {final_acc:.4f}\")\n","    print(\"  Per-class F1 scores:\")\n","    for i, cls in enumerate([\"W\",\"N1\",\"N2\",\"N3\",\"REM\"]):\n","        print(f\"    {cls}: {final_report[cls]['f1-score']:.4f}\")\n","        all_fold_f1[k, i] = final_report[cls]['f1-score']\n","\n","    print(\"\\n  Confusion Matrix:\")\n","    print(\"    W    N1    N2    N3    REM\")\n","    for i in range(5):\n","        row_str = \"  \" + \" \".join(f\"{final_cm[i,j]:5d}\" for j in range(5))\n","        print(f\"{['W','N1','N2','N3','REM'][i]}: {row_str}\")\n","\n","    # Accumulate confusion matrix\n","    all_fold_confusion += final_cm\n","\n","    # Store results for this fold\n","    fold_results['accuracy'].append(final_acc)\n","    fold_results['f1_wake'].append(final_report['W']['f1-score'])\n","    fold_results['f1_n1'].append(final_report['N1']['f1-score'])\n","    fold_results['f1_n2'].append(final_report['N2']['f1-score'])\n","    fold_results['f1_n3'].append(final_report['N3']['f1-score'])\n","    fold_results['f1_rem'].append(final_report['REM']['f1-score'])\n","\n","    # Save detailed results for this fold\n","    np.savez(\n","        RESULTS_DIR/f\"metrics/fold{k+1}_results.npz\",\n","        predictions=final_preds,\n","        labels=final_labels,\n","        confusion_matrix=final_cm,\n","        report=final_report\n","    )\n","\n","# Print overall cross-validation summary\n","print(\"\\n=== Cross-Validation Summary ===\")\n","print(\"Fold accuracies:\", fold_results['accuracy'])\n","print(f\"Mean accuracy: {np.mean(fold_results['accuracy']):.4f} ± {np.std(fold_results['accuracy']):.4f}\")\n","\n","print(\"\\nPer-class F1 scores across folds:\")\n","for cls, key in zip([\"W\",\"N1\",\"N2\",\"N3\",\"REM\"],\n","                    ['f1_wake', 'f1_n1', 'f1_n2', 'f1_n3', 'f1_rem']):\n","    print(f\"  {cls}: {np.mean(fold_results[key]):.4f} ± {np.std(fold_results[key]):.4f}\")\n","\n","# Print overall confusion matrix\n","print(\"\\nOverall Confusion Matrix:\")\n","print(\"      W      N1      N2      N3      REM\")\n","for i in range(5):\n","    row_str = \"  \" + \" \".join(f\"{all_fold_confusion[i,j]:7.0f}\" for j in range(5))\n","    print(f\"{['W','N1','N2','N3','REM'][i]}: {row_str}\")\n","\n","# Calculate per-class metrics from overall confusion matrix\n","precision = np.zeros(5)\n","recall = np.zeros(5)\n","f1 = np.zeros(5)\n","\n","for i in range(5):\n","    # Precision: TP / (TP + FP)\n","    precision[i] = all_fold_confusion[i, i] / np.sum(all_fold_confusion[:, i]) if np.sum(all_fold_confusion[:, i]) \u003e 0 else 0\n","    # Recall: TP / (TP + FN)\n","    recall[i] = all_fold_confusion[i, i] / np.sum(all_fold_confusion[i, :]) if np.sum(all_fold_confusion[i, :]) \u003e 0 else 0\n","    # F1: 2 * precision * recall / (precision + recall)\n","    f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i]) if (precision[i] + recall[i]) \u003e 0 else 0\n","\n","print(\"\\nOverall Per-class Metrics:\")\n","for i, cls in enumerate([\"W\",\"N1\",\"N2\",\"N3\",\"REM\"]):\n","    print(f\"  {cls}: Precision={precision[i]:.4f}, Recall={recall[i]:.4f}, F1={f1[i]:.4f}\")\n","\n","np.savez(\n","    RESULTS_DIR/\"metrics/cv_summary.npz\",\n","    fold_accuracies=fold_results['accuracy'],\n","    fold_f1_scores=all_fold_f1,\n","    overall_confusion=all_fold_confusion,\n","    overall_precision=precision,\n","    overall_recall=recall,\n","    overall_f1=f1\n",")\n","\n","print(\"\\nTraining completed. Results saved to:\", RESULTS_DIR)\n","\n","# new\n","def mixup_batch(raw, c22, labels, alpha=0.2):\n","  \"\"\"Apply mixup augmentation to a batch.\n","\n","  Args:\n","    raw: Raw EEG/EOG data tensor\n","    c22: Catch22 features tensor\n","    labels: Target labels tensor\n","    alpha: Mixup interpolation strength parameter\n","\n","  Returns:\n","    Tuple of (mixed_raw, mixed_c22, labels_a, labels_b, lambda)\n","  \"\"\"\n","  if alpha \u003e 0:\n","    lam = np.random.beta(alpha, alpha)\n","  else:\n","    lam = 1\n","\n","  batch_size = raw.size(0)\n","  index = torch.randperm(batch_size).to(raw.device)\n","\n","  mixed_raw = lam * raw + (1 - lam) * raw[index]\n","  mixed_c22 = lam * c22 + (1 - lam) * c22[index]\n","  return mixed_raw, mixed_c22, labels, labels[index], lam"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMm4NPhZg8T4cXaue0+lm0G","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}