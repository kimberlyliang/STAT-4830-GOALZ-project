{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# orig name was cnn_tfm_fcl_n1.py in my separate branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, sys, glob, argparse, numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# PROCESSED_DATA_DIR = '/content/drive/MyDrive/spring_2025/STAT_4830/4830_project/sleepedf_data/processed_sleepedf'\n",
    "PROCESSED_DATA_DIR = '/users/okalova/sleep/STAT-4830-GOALZ-project/data/processed_sleepedf'\n",
    "\n",
    "# new - not included in the most recent run\n",
    "import random\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 32\n",
    "# NUM_EPOCHS = 10\n",
    "NUM_EPOCHS = 35\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAIN_RATIO = 0.8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEQ_LENGTH = 20\n",
    "\n",
    "try:\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"No GPU available; using CPU\")\n",
    "except Exception as e:\n",
    "    use_gpu = False\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Error checking GPU: {e}. Using CPU.\")\n",
    "\n",
    "def get_true_subject_id(filename):\n",
    "    \"\"\"Extract true subject ID ignoring the night number\"\"\"\n",
    "    basename = os.path.basename(filename).split('_')[0]\n",
    "    if basename.startswith('SC4'):\n",
    "        return basename[:5]  # SC4xx - first 5 chars for Sleep Cassette\n",
    "    elif basename.startswith('ST7'):\n",
    "        return basename[:5]  # ST7xx - first 5 chars for Sleep Telemetry\n",
    "    else:\n",
    "        return basename[:6]  # Fallback to original logic\n",
    "\n",
    "def group_by_true_subjects(data_dir):\n",
    "    \"\"\"Map true subject IDs to their recording IDs\"\"\"\n",
    "    all_files = glob.glob(os.path.join(data_dir, '*_sequences.npz'))\n",
    "    \n",
    "    true_subject_map = {}\n",
    "    for f in all_files:\n",
    "        recording_id = os.path.basename(f).split('_')[0]\n",
    "        true_subject = get_true_subject_id(f)\n",
    "        \n",
    "        if true_subject not in true_subject_map:\n",
    "            true_subject_map[true_subject] = []\n",
    "        true_subject_map[true_subject].append(recording_id)\n",
    "    \n",
    "    print(f\"Found {len(true_subject_map)} unique subjects\")\n",
    "    \n",
    "    return true_subject_map\n",
    "\n",
    "def split_true_subjects(data_dir, train_ratio=0.8, random_state=42):\n",
    "    \"\"\"Split data by true subject IDs (not by recording/night)\"\"\"\n",
    "    true_subject_map = group_by_true_subjects(data_dir)\n",
    "    \n",
    "    true_subjects = list(true_subject_map.keys())\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(true_subjects)\n",
    "    \n",
    "    n_train = int(len(true_subjects) * train_ratio)\n",
    "    train_true_subjects = true_subjects[:n_train]\n",
    "    test_true_subjects = true_subjects[n_train:]\n",
    "    \n",
    "    train_recording_ids = []\n",
    "    for subject in train_true_subjects:\n",
    "        train_recording_ids.extend(true_subject_map[subject])\n",
    "    \n",
    "    test_recording_ids = []\n",
    "    for subject in test_true_subjects:\n",
    "        test_recording_ids.extend(true_subject_map[subject])\n",
    "    \n",
    "    print(f\"Training on {len(train_recording_ids)} recordings from {len(train_true_subjects)} subjects\")\n",
    "    print(f\"Testing on {len(test_recording_ids)} recordings from {len(test_true_subjects)} subjects\")\n",
    "    \n",
    "    return train_recording_ids, test_recording_ids\n",
    "\n",
    "class SleepSequenceDataset(Dataset):\n",
    "    def __init__(self, data_dir, patient_ids=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Directory containing the preprocessed NPZ files\n",
    "            patient_ids: List of patient IDs to include (e.g., ['SC4252', 'SC4231'])\n",
    "        \"\"\"\n",
    "        # Get all sequence files\n",
    "        all_files = glob.glob(os.path.join(data_dir, '*_sequences.npz'))\n",
    "        \n",
    "        # Filter by patient IDs if specified\n",
    "        if patient_ids is not None:\n",
    "            self.files = [f for f in all_files if any(pid in os.path.basename(f) for pid in patient_ids)]\n",
    "        else:\n",
    "            self.files = all_files\n",
    "            \n",
    "        sequences_list = []\n",
    "        labels_list = []\n",
    "        self.patient_ids = []\n",
    "        self.true_subject_ids = []\n",
    "        \n",
    "        for f in self.files:\n",
    "            loaded = np.load(f)\n",
    "            sequences_list.append(loaded['sequences'])\n",
    "            labels_list.append(loaded['seq_labels'])\n",
    "            recording_id = os.path.basename(f).split('_')[0]\n",
    "            true_subject = get_true_subject_id(f)\n",
    "            \n",
    "            self.patient_ids.append(recording_id)\n",
    "            self.true_subject_ids.append(true_subject)\n",
    "            \n",
    "        self.sequences = np.concatenate(sequences_list, axis=0)\n",
    "        self.seq_labels = np.concatenate(labels_list, axis=0)\n",
    "        self.sequences = torch.from_numpy(self.sequences).float()\n",
    "        self.seq_labels = torch.from_numpy(self.seq_labels).long()\n",
    "        \n",
    "        print(f\"Loaded {len(self.files)} files from {len(set(self.true_subject_ids))} unique subjects\")\n",
    "        print(f\"Total sequences: {len(self.sequences)}\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        unique, counts = np.unique(self.seq_labels.numpy().flatten(), return_counts=True)\n",
    "        print(\"\\nClass distribution:\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            print(f\"Class {label} ({'W N1 N2 N3 REM'.split()[label]}): {count} samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sequences.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.seq_labels[idx]\n",
    "\n",
    "def create_balanced_sampler(dataset):\n",
    "    \"\"\"\n",
    "    Create a weighted sampler to balance class distributions\n",
    "    \"\"\"\n",
    "    # Get all labels (we'll use the first label of each sequence since sequences are contiguous)\n",
    "    all_labels = dataset.seq_labels[:, 0].numpy()  # Only take first label of each sequence\n",
    "    \n",
    "    # Compute class weights\n",
    "    classes = np.unique(all_labels)\n",
    "    class_weights = {}\n",
    "    total_samples = len(all_labels)\n",
    "    for c in classes:\n",
    "        class_weights[c] = float(total_samples) / (len(classes) * np.sum(all_labels == c))\n",
    "    \n",
    "    # Create sample weights\n",
    "    sample_weights = np.array([class_weights[label] for label in all_labels])\n",
    "    \n",
    "    # Create sampler with length equal to dataset\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(dataset),  # Use actual dataset length\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    return sampler, torch.FloatTensor([class_weights[c] for c in sorted(class_weights.keys())])\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class EpochEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        # Let's calculate the correct dimension\n",
    "        self.calculate_fc_input_dim = None  # Will be set in forward pass\n",
    "        self.fc = None  # Will be initialized in first forward pass\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, channels, time_points)\n",
    "        batch_size, seq_len, channels, time_points = x.shape\n",
    "        \n",
    "        # Process each sequence element independently\n",
    "        x = x.view(batch_size * seq_len, channels, time_points)\n",
    "        \n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        \n",
    "        # Initialize fc layer if not done yet\n",
    "        if self.fc is None:\n",
    "            self.calculate_fc_input_dim = x.shape[1] * x.shape[2]\n",
    "            self.fc = nn.Linear(self.calculate_fc_input_dim, self.embedding_dim).to(x.device)\n",
    "            print(f\"Initialized fc layer with input dim: {self.calculate_fc_input_dim}\")\n",
    "        \n",
    "        x = x.view(batch_size * seq_len, -1)  # Flatten\n",
    "        x = self.dropout(torch.relu(self.fc(x)))\n",
    "        \n",
    "        # Reshape back to sequence form\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        return x\n",
    "\n",
    "class SleepTransformer(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, num_classes=5, num_layers=2, num_heads=4, dropout=0.1, seq_length=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.epoch_encoder = EpochEncoder(embedding_dim)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, seq_length, embedding_dim))\n",
    "        \n",
    "        # Transformer layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=4*embedding_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(embedding_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, channels, time_points)\n",
    "        \n",
    "        # Get embeddings for each epoch\n",
    "        x = self.epoch_encoder(x)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_encoder\n",
    "        \n",
    "        # Pass through transformer\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Get predictions for each time step\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def focal_loss_with_n1_focus(inputs, targets, alpha_general=0.25, alpha_n1=0.75, gamma=2):\n",
    "    \"\"\"\n",
    "    Focal Loss with specific focus on N1 class (class index 1)\n",
    "    - alpha_general: weight for all non-N1 classes\n",
    "    - alpha_n1: higher weight specifically for N1 class\n",
    "    - gamma: focusing parameter - same as standard focal loss\n",
    "    \"\"\"\n",
    "    # Get class dimension\n",
    "    num_classes = inputs.size(-1)\n",
    "    \n",
    "    # Create one-hot encoded targets\n",
    "    one_hot_targets = F.one_hot(targets, num_classes=num_classes)\n",
    "    \n",
    "    # Calculate standard cross entropy (per element)\n",
    "    ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    \n",
    "    # Create a mask for N1 instances (where target == 1)\n",
    "    n1_mask = (targets == 1).float()\n",
    "    \n",
    "    # Apply different alpha values for N1 vs other classes\n",
    "    alphas = alpha_general * (1 - n1_mask) + alpha_n1 * n1_mask\n",
    "    \n",
    "    # Calculate the full focal loss with the appropriate alpha per sample\n",
    "    loss = alphas * ((1 - pt) ** gamma) * ce_loss\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def focal_loss_with_n1_focus(inputs, targets, alpha_general=0.25, alpha_n1=0.75, gamma=2):\n",
    "    \"\"\"\n",
    "    Focal Loss with specific focus on N1 class (class index 1)\n",
    "    - alpha_general: weight for all non-N1 classes\n",
    "    - alpha_n1: higher weight specifically for N1 class\n",
    "    - gamma: focusing parameter - same as standard focal loss\n",
    "    \"\"\"\n",
    "    # Get class dimension\n",
    "    num_classes = inputs.size(-1)\n",
    "    \n",
    "    # Create one-hot encoded targets\n",
    "    one_hot_targets = F.one_hot(targets, num_classes=num_classes)\n",
    "    \n",
    "    # Calculate standard cross entropy (per element)\n",
    "    ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    \n",
    "    # Create a mask for N1 instances (where target == 1)\n",
    "    n1_mask = (targets == 1).float()\n",
    "    \n",
    "    # Apply different alpha values for N1 vs other classes\n",
    "    alphas = alpha_general * (1 - n1_mask) + alpha_n1 * n1_mask\n",
    "    \n",
    "    # Calculate the full focal loss with the appropriate alpha per sample\n",
    "    loss = alphas * ((1 - pt) ** gamma) * ce_loss\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "# def focal_loss(inputs, targets, alpha=0.25, gamma=2):\n",
    "#     \"\"\"\n",
    "#     Focal Loss for handling class imbalance\n",
    "#     \"\"\"\n",
    "#     ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#     pt = torch.exp(-ce_loss)\n",
    "#     loss = alpha * ((1 - pt) ** gamma) * ce_loss\n",
    "#     return loss.mean()\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for seq, labels in dataloader:\n",
    "        seq, labels = seq.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(seq)\n",
    "        loss = criterion(logits.view(-1, 5), labels.view(-1))  # 5 classes\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * seq.size(0)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.append(preds.cpu().detach().numpy())\n",
    "        all_labels.append(labels.cpu().detach().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    all_preds = np.concatenate(all_preds).flatten()\n",
    "    all_labels = np.concatenate(all_labels).flatten()\n",
    "    acc = (all_preds == all_labels).mean()\n",
    "    \n",
    "    return epoch_loss, acc\n",
    "\n",
    "def eval_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation data\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq, labels in dataloader:\n",
    "            seq, labels = seq.to(device), labels.to(device)\n",
    "            logits = model(seq)\n",
    "            loss = criterion(logits.view(-1, 5), labels.view(-1))  # 5 classes\n",
    "            \n",
    "            running_loss += loss.item() * seq.size(0)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    all_preds = np.concatenate(all_preds).flatten()\n",
    "    all_labels = np.concatenate(all_labels).flatten()\n",
    "    all_probs = np.concatenate(all_probs).reshape(-1, 5)  # 5 classes\n",
    "    acc = (all_preds == all_labels).mean()\n",
    "    \n",
    "    return epoch_loss, acc, all_preds, all_labels, all_probs\n",
    "\n",
    "def plot_curves(train_losses, test_losses, train_accs, test_accs):\n",
    "    \"\"\"Plot training and validation curves\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(test_losses, label='Test Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Loss Curves')\n",
    "    \n",
    "    ax2.plot(train_accs, label='Train Acc')\n",
    "    ax2.plot(test_accs, label='Test Acc')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Accuracy Curves')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "def median_smoothing(predictions, kernel_size=3):\n",
    "    \"\"\"Apply median smoothing to predictions\"\"\"\n",
    "    return median_filter(predictions, size=kernel_size)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute classification metrics\"\"\"\n",
    "    return {\n",
    "        'classification_report': classification_report(y_true, y_pred, target_names=[\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]),\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(5)\n",
    "    plt.xticks(tick_marks, [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"])\n",
    "    plt.yticks(tick_marks, [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Split patients into train and test sets\n",
    "    train_patients, test_patients = split_true_subjects(PROCESSED_DATA_DIR, train_ratio=TRAIN_RATIO)\n",
    "    \n",
    "    # Create datasets with specific patients\n",
    "    train_dataset = SleepSequenceDataset(PROCESSED_DATA_DIR, patient_ids=train_patients)\n",
    "    test_dataset = SleepSequenceDataset(PROCESSED_DATA_DIR, patient_ids=test_patients)\n",
    "    \n",
    "    # Create balanced sampler and get class weights\n",
    "    train_sampler, class_weights = create_balanced_sampler(train_dataset)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=2\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SleepTransformer(\n",
    "        embedding_dim=128,\n",
    "        num_classes=5,\n",
    "        num_layers=2,\n",
    "        num_heads=4,\n",
    "        dropout=0.1,\n",
    "        seq_length=SEQ_LENGTH\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # Use focal loss with class weights\n",
    "    class_weights = class_weights.to(device)\n",
    "    # criterion = lambda x, y: focal_loss(x, y, alpha=0.25, gamma=2)\n",
    "    criterion = lambda x, y: focal_loss_with_n1_focus(x, y, alpha_general=0.25, alpha_n1=0.75, gamma=2)\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accs, test_accs = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss, val_acc, val_preds, val_labels, val_probs = eval_epoch(\n",
    "            model, test_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save metrics\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Print detailed metrics every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0 or epoch == NUM_EPOCHS - 1:\n",
    "            metrics = compute_metrics(val_labels, val_preds)\n",
    "            print(\"\\nDetailed Metrics:\")\n",
    "            print(metrics['classification_report'])\n",
    "            \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Final evaluation\n",
    "    val_loss, val_acc, val_preds, val_labels, val_probs = eval_epoch(\n",
    "        model, test_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Apply median smoothing to final predictions\n",
    "    smoothed_preds = median_smoothing(val_preds, kernel_size=5)\n",
    "    \n",
    "    # Compute and print final metrics\n",
    "    print(\"\\nFinal Metrics (with smoothing):\")\n",
    "    final_metrics = compute_metrics(val_labels, smoothed_preds)\n",
    "    print(final_metrics['classification_report'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(final_metrics['confusion_matrix'])\n",
    "    \n",
    "    # Plot training curves\n",
    "    plot_curves(train_losses, test_losses, train_accs, test_accs)\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save({\n",
    "        'model_state_dict': best_model_state,\n",
    "        'train_patients': train_patients,\n",
    "        'test_patients': test_patients,\n",
    "        'final_metrics': final_metrics,\n",
    "    }, 'sleep_transformer_model.pth')\n",
    "    \n",
    "    print(\"Training complete. Model and results saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnt_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
