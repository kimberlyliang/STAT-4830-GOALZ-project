SELF-CRITIQUE: Bottlenecks and Areas for Improvement in the Sleep Stage Classification Pipeline

Our current implementation of the sleep staging pipeline—while conceptually robust—exhibits several limitations that must be addressed to enhance its practicality and scalability. One major bottleneck is the extended processing time required for feature extraction. Although the catch22 feature set is designed for speed, our current sequential implementation processes each subject, epoch, and electrode one at a time. This lack of parallelization significantly increases the runtime, particularly when processing full 24-hour recordings. The large size of the EDF files further exacerbates I/O delays.

Another limitation is the fixed parameter configuration used in both the PSD-based and catch22-based feature extraction methods. Choices such as the Butterworth filter cutoff frequencies, epoch duration, and segmentation strategy were predetermined and may not be optimal for all subjects. This rigidity could result in suboptimal feature representations, especially for subtle transitions between relaxed wakefulness and light sleep. Furthermore, while the engineered features provide a degree of interpretability, they may not capture the full complexity of the EEG signal dynamics, thereby limiting the ability to detect meaningful biomarkers.

From a methodological standpoint, our current approach relies exclusively on engineered feature extraction. Although this provides valuable insight into the underlying physiological processes, it does not leverage the full potential of data-driven methods. Deep learning architectures—such as TCNs, CNNs, and GNNs—offer an attractive alternative as they can learn hierarchical representations directly from raw EEG data without manual feature selection. However, the integration of these models into our pipeline presents its own challenges, including the need for large amounts of labeled data and significant computational resources for training.

In summary, our self-critique highlights the need for parallelization to overcome compute-time bottlenecks, more adaptive parameter tuning to improve feature quality, and the exploration of advanced deep learning techniques to complement or replace the current engineered features. Addressing these challenges will be critical for developing a robust and generalizable sleep staging model that can operate effectively on full 24-hour recordings and potentially reveal novel biomarkers for sleep onset and circadian regulation.